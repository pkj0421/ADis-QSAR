2023-05-26 22:00:34,624 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_80\ECFP6_256bits\MinMax\BTK_train_vector.tsv
2023-05-26 22:00:34,624 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_80\ECFP6_256bits\MinMax\BTK_valid_vector.tsv
2023-05-26 22:00:34,625 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_80\ECFP6_256bits\MinMax\BTK_model\SVM
2023-05-26 22:00:34,625 [INFO] Model type : SVM
2023-05-26 22:00:34,625 [INFO] Use cores : 12
2023-05-26 22:00:34,645 [INFO] Start Learning model
2023-05-26 22:00:34,645 [INFO] Train : 578 | Valid : 152
2023-05-26 22:00:34,645 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 22:00:38,928 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.942892              0.938750        0.935304
0              0.923896              0.919234        0.913227
2              0.923896              0.919234        0.913227
4              0.923896              0.919234        0.913227
6              0.923896              0.919234        0.913227
8              0.923896              0.919234        0.913227
41             0.944616              0.912965        0.943463
51             0.944616              0.912965        0.943463
31             0.942892              0.912603        0.941190
12             0.904930              0.881938        0.895344
18             0.904930              0.881938        0.895344
16             0.904930              0.881938        0.895344
14             0.904930              0.881938        0.895344
10             0.904930              0.881938        0.895344
50             0.880611              0.844893        0.869952
48             0.880611              0.844893        0.869952
52             0.880611              0.844893        0.869952
46             0.880611              0.844893        0.869952
54             0.880611              0.844893        0.869952
44             0.880611              0.844893        0.869952
42             0.880611              0.844893        0.869952
56             0.880611              0.844893        0.869952
58             0.880611              0.844893        0.869952
40             0.880611              0.844893        0.869952
38             0.880611              0.844893        0.869952
36             0.880611              0.844893        0.869952
34             0.880611              0.844893        0.869952
32             0.880611              0.844893        0.869952
30             0.880611              0.844893        0.869952
24             0.880611              0.844893        0.869952
28             0.880611              0.844893        0.869952
26             0.880611              0.844893        0.869952
20             0.880611              0.844893        0.869952
22             0.880611              0.844893        0.869952
33             0.669510              0.800000        0.551190
53             0.669510              0.800000        0.551190
43             0.669510              0.800000        0.551190
23             0.638385              0.400000        0.509416
11             0.631488              0.000000        0.500000
9              0.631488              0.000000        0.500000
29             0.631488              0.000000        0.500000
7              0.631488              0.000000        0.500000
49             0.631488              0.000000        0.500000
55             0.631488              0.000000        0.500000
5              0.631488              0.000000        0.500000
57             0.631488              0.000000        0.500000
3              0.631488              0.000000        0.500000
13             0.631488              0.000000        0.500000
19             0.631488              0.000000        0.500000
15             0.631488              0.000000        0.500000
47             0.631488              0.000000        0.500000
17             0.631488              0.000000        0.500000
45             0.631488              0.000000        0.500000
1              0.631488              0.000000        0.500000
39             0.631488              0.000000        0.500000
37             0.631488              0.000000        0.500000
25             0.631488              0.000000        0.500000
35             0.631488              0.000000        0.500000
27             0.631488              0.000000        0.500000
59             0.631488              0.000000        0.500000
2023-05-26 22:00:38,930 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-26 22:00:38,958 [INFO] Save train_prediction_log data...
2023-05-26 22:00:38,962 [INFO] {'Data': 'train', 'ACC': '0.97 (563 / 578)', 'TP': 204, 'FP': 6, 'FN': 9, 'TN': 359, 'Precision': '0.97 (204 / 204 + 6)', 'Recall': '0.96 (204 / 204 + 9)', 'F1': '0.96 (2 * (0.96 * 0.97) / 0.96 + 0.97)', 'Specificity': '0.98 (359 / 359 + 6)', 'AUC': 0.97, 'r2': 0.89}
2023-05-26 22:00:38,971 [INFO] Save valid_prediction_log data...
2023-05-26 22:00:38,973 [INFO] {'Data': 'valid', 'ACC': '0.95 (145 / 152)', 'TP': 56, 'FP': 2, 'FN': 5, 'TN': 89, 'Precision': '0.97 (56 / 56 + 2)', 'Recall': '0.92 (56 / 56 + 5)', 'F1': '0.94 (2 * (0.92 * 0.97) / 0.92 + 0.97)', 'Specificity': '0.98 (89 / 89 + 2)', 'AUC': 0.95, 'r2': 0.81}
2023-05-26 22:00:38,989 [INFO] Save test_prediction_log data...
2023-05-26 22:00:38,991 [INFO] {'Data': 'test', 'ACC': '0.97 (146 / 151)', 'TP': 59, 'FP': 4, 'FN': 1, 'TN': 87, 'Precision': '0.94 (59 / 59 + 4)', 'Recall': '0.98 (59 / 59 + 1)', 'F1': '0.96 (2 * (0.98 * 0.94) / 0.98 + 0.94)', 'Specificity': '0.96 (87 / 87 + 4)', 'AUC': 0.97, 'r2': 0.86}
2023-05-26 22:00:38,993 [INFO] Save training_log data...
2023-05-26 22:00:38,995 [INFO] Save score_log data...
2023-05-26 22:00:38,996 [INFO] Time : 4.372348070144653
