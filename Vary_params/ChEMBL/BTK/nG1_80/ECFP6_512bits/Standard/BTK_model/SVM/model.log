2023-05-26 23:53:26,810 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_80\ECFP6_512bits\Standard\BTK_train_vector.tsv
2023-05-26 23:53:26,810 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_80\ECFP6_512bits\Standard\BTK_valid_vector.tsv
2023-05-26 23:53:26,810 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_80\ECFP6_512bits\Standard\BTK_model\SVM
2023-05-26 23:53:26,810 [INFO] Model type : SVM
2023-05-26 23:53:26,810 [INFO] Use cores : 12
2023-05-26 23:53:26,873 [INFO] Start Learning model
2023-05-26 23:53:26,873 [INFO] Train : 578 | Valid : 152
2023-05-26 23:53:26,873 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 23:53:34,544 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.916999              0.899156        0.908814
2              0.916999              0.899156        0.908814
4              0.916999              0.899156        0.908814
6              0.916999              0.899156        0.908814
8              0.916999              0.899156        0.908814
44             0.913491              0.881312        0.908904
28             0.913491              0.881312        0.908904
32             0.913491              0.881312        0.908904
34             0.913491              0.881312        0.908904
36             0.913491              0.881312        0.908904
38             0.913491              0.881312        0.908904
40             0.913491              0.881312        0.908904
42             0.913491              0.881312        0.908904
48             0.913491              0.881312        0.908904
46             0.913491              0.881312        0.908904
24             0.913491              0.881312        0.908904
50             0.913491              0.881312        0.908904
52             0.913491              0.881312        0.908904
54             0.913491              0.881312        0.908904
56             0.913491              0.881312        0.908904
58             0.913491              0.881312        0.908904
26             0.913491              0.881312        0.908904
30             0.913491              0.881312        0.908904
12             0.913491              0.881312        0.908904
18             0.913491              0.881312        0.908904
14             0.913491              0.881312        0.908904
22             0.913491              0.881312        0.908904
16             0.913491              0.881312        0.908904
20             0.913491              0.881312        0.908904
10             0.913491              0.881312        0.908904
51             0.636661              0.300000        0.507035
41             0.636661              0.300000        0.507035
31             0.636661              0.300000        0.507035
53             0.631488              0.000000        0.500000
45             0.631488              0.000000        0.500000
7              0.631488              0.000000        0.500000
55             0.631488              0.000000        0.500000
49             0.631488              0.000000        0.500000
5              0.631488              0.000000        0.500000
11             0.631488              0.000000        0.500000
47             0.631488              0.000000        0.500000
57             0.631488              0.000000        0.500000
3              0.631488              0.000000        0.500000
9              0.631488              0.000000        0.500000
23             0.631488              0.000000        0.500000
13             0.631488              0.000000        0.500000
43             0.631488              0.000000        0.500000
15             0.631488              0.000000        0.500000
39             0.631488              0.000000        0.500000
37             0.631488              0.000000        0.500000
17             0.631488              0.000000        0.500000
35             0.631488              0.000000        0.500000
33             0.631488              0.000000        0.500000
19             0.631488              0.000000        0.500000
1              0.631488              0.000000        0.500000
29             0.631488              0.000000        0.500000
27             0.631488              0.000000        0.500000
21             0.631488              0.000000        0.500000
25             0.631488              0.000000        0.500000
59             0.631488              0.000000        0.500000
2023-05-26 23:53:34,545 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-26 23:53:34,561 [INFO] Save train_prediction_log data...
2023-05-26 23:53:34,584 [INFO] {'Data': 'train', 'ACC': '1.0 (576 / 578)', 'TP': 212, 'FP': 1, 'FN': 1, 'TN': 364, 'Precision': '1.0 (212 / 212 + 1)', 'Recall': '1.0 (212 / 212 + 1)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (364 / 364 + 1)', 'AUC': 1.0, 'r2': 0.99}
2023-05-26 23:53:34,592 [INFO] Save valid_prediction_log data...
2023-05-26 23:53:34,594 [INFO] {'Data': 'valid', 'ACC': '0.96 (146 / 152)', 'TP': 57, 'FP': 2, 'FN': 4, 'TN': 89, 'Precision': '0.97 (57 / 57 + 2)', 'Recall': '0.93 (57 / 57 + 4)', 'F1': '0.95 (2 * (0.93 * 0.97) / 0.93 + 0.97)', 'Specificity': '0.98 (89 / 89 + 2)', 'AUC': 0.96, 'r2': 0.84}
2023-05-26 23:53:34,619 [INFO] Save test_prediction_log data...
2023-05-26 23:53:34,621 [INFO] {'Data': 'test', 'ACC': '0.99 (150 / 151)', 'TP': 60, 'FP': 1, 'FN': 0, 'TN': 90, 'Precision': '0.98 (60 / 60 + 1)', 'Recall': '1.0 (60 / 60 + 0)', 'F1': '0.99 (2 * (1.0 * 0.98) / 1.0 + 0.98)', 'Specificity': '0.99 (90 / 90 + 1)', 'AUC': 0.99, 'r2': 0.97}
2023-05-26 23:53:34,623 [INFO] Save training_log data...
2023-05-26 23:53:34,624 [INFO] Save score_log data...
2023-05-26 23:53:34,625 [INFO] Time : 7.815165042877197
