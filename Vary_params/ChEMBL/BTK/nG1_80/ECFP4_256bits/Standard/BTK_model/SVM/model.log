2023-05-26 17:04:57,194 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_80\ECFP4_256bits\Standard\BTK_train_vector.tsv
2023-05-26 17:04:57,194 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_80\ECFP4_256bits\Standard\BTK_valid_vector.tsv
2023-05-26 17:04:57,194 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_80\ECFP4_256bits\Standard\BTK_model\SVM
2023-05-26 17:04:57,194 [INFO] Model type : SVM
2023-05-26 17:04:57,194 [INFO] Use cores : 12
2023-05-26 17:04:57,234 [INFO] Start Learning model
2023-05-26 17:04:57,234 [INFO] Train : 578 | Valid : 152
2023-05-26 17:04:57,234 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 17:05:01,704 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.929189              0.978036        0.907977
41             0.932607              0.973274        0.913623
31             0.932607              0.973274        0.913623
51             0.932607              0.973274        0.913623
0              0.935935              0.921292        0.929715
2              0.935935              0.921292        0.929715
4              0.935935              0.921292        0.929715
6              0.935935              0.921292        0.929715
8              0.935935              0.921292        0.929715
12             0.906382              0.870772        0.902248
18             0.906382              0.870772        0.902248
16             0.906382              0.870772        0.902248
14             0.906382              0.870772        0.902248
10             0.906382              0.870772        0.902248
50             0.894283              0.861029        0.887712
48             0.894283              0.861029        0.887712
52             0.894283              0.861029        0.887712
46             0.894283              0.861029        0.887712
54             0.894283              0.861029        0.887712
44             0.894283              0.861029        0.887712
42             0.894283              0.861029        0.887712
56             0.894283              0.861029        0.887712
58             0.894283              0.861029        0.887712
40             0.894283              0.861029        0.887712
38             0.894283              0.861029        0.887712
36             0.894283              0.861029        0.887712
34             0.894283              0.861029        0.887712
32             0.894283              0.861029        0.887712
30             0.894283              0.861029        0.887712
24             0.894283              0.861029        0.887712
28             0.894283              0.861029        0.887712
26             0.894283              0.861029        0.887712
20             0.894283              0.861029        0.887712
22             0.894283              0.861029        0.887712
53             0.631488              0.000000        0.500000
49             0.631488              0.000000        0.500000
13             0.631488              0.000000        0.500000
11             0.631488              0.000000        0.500000
9              0.631488              0.000000        0.500000
29             0.631488              0.000000        0.500000
47             0.631488              0.000000        0.500000
7              0.631488              0.000000        0.500000
55             0.631488              0.000000        0.500000
5              0.631488              0.000000        0.500000
57             0.631488              0.000000        0.500000
3              0.631488              0.000000        0.500000
15             0.631488              0.000000        0.500000
19             0.631488              0.000000        0.500000
17             0.631488              0.000000        0.500000
45             0.631488              0.000000        0.500000
1              0.631488              0.000000        0.500000
43             0.631488              0.000000        0.500000
23             0.631488              0.000000        0.500000
39             0.631488              0.000000        0.500000
37             0.631488              0.000000        0.500000
25             0.631488              0.000000        0.500000
35             0.631488              0.000000        0.500000
33             0.631488              0.000000        0.500000
27             0.631488              0.000000        0.500000
59             0.631488              0.000000        0.500000
2023-05-26 17:05:01,705 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-26 17:05:01,748 [INFO] Save train_prediction_log data...
2023-05-26 17:05:01,752 [INFO] {'Data': 'train', 'ACC': '1.0 (577 / 578)', 'TP': 212, 'FP': 0, 'FN': 1, 'TN': 365, 'Precision': '1.0 (212 / 212 + 0)', 'Recall': '1.0 (212 / 212 + 1)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (365 / 365 + 0)', 'AUC': 1.0, 'r2': 0.99}
2023-05-26 17:05:01,766 [INFO] Save valid_prediction_log data...
2023-05-26 17:05:01,768 [INFO] {'Data': 'valid', 'ACC': '0.98 (149 / 152)', 'TP': 58, 'FP': 0, 'FN': 3, 'TN': 91, 'Precision': '1.0 (58 / 58 + 0)', 'Recall': '0.95 (58 / 58 + 3)', 'F1': '0.97 (2 * (0.95 * 1.0) / 0.95 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.98, 'r2': 0.92}
2023-05-26 17:05:01,791 [INFO] Save test_prediction_log data...
2023-05-26 17:05:01,793 [INFO] {'Data': 'test', 'ACC': '0.98 (148 / 151)', 'TP': 57, 'FP': 0, 'FN': 3, 'TN': 91, 'Precision': '1.0 (57 / 57 + 0)', 'Recall': '0.95 (57 / 57 + 3)', 'F1': '0.97 (2 * (0.95 * 1.0) / 0.95 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.98, 'r2': 0.92}
2023-05-26 17:05:01,796 [INFO] Save training_log data...
2023-05-26 17:05:01,805 [INFO] Save score_log data...
2023-05-26 17:05:01,805 [INFO] Time : 4.611432313919067
