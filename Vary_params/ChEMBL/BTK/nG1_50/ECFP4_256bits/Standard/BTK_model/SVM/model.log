2023-05-26 07:39:24,782 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_256bits\Standard\BTK_train_vector.tsv
2023-05-26 07:39:24,783 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_256bits\Standard\BTK_valid_vector.tsv
2023-05-26 07:39:24,783 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_256bits\Standard\BTK_model\SVM
2023-05-26 07:39:24,783 [INFO] Model type : SVM
2023-05-26 07:39:24,783 [INFO] Use cores : 12
2023-05-26 07:39:24,818 [INFO] Start Learning model
2023-05-26 07:39:24,819 [INFO] Train : 608 | Valid : 152
2023-05-26 07:39:24,819 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 07:39:29,135 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.939153              0.960999        0.930113
31             0.934235              0.949166        0.925946
51             0.934235              0.949166        0.925946
41             0.934235              0.949166        0.925946
0              0.911202              0.903680        0.905505
2              0.911202              0.903680        0.905505
4              0.911202              0.903680        0.905505
6              0.911202              0.903680        0.905505
8              0.911202              0.903680        0.905505
42             0.907869              0.892621        0.904032
32             0.907869              0.892621        0.904032
34             0.907869              0.892621        0.904032
36             0.907869              0.892621        0.904032
38             0.907869              0.892621        0.904032
40             0.907869              0.892621        0.904032
48             0.907869              0.892621        0.904032
44             0.907869              0.892621        0.904032
46             0.907869              0.892621        0.904032
26             0.907869              0.892621        0.904032
50             0.907869              0.892621        0.904032
52             0.907869              0.892621        0.904032
54             0.907869              0.892621        0.904032
56             0.907869              0.892621        0.904032
58             0.907869              0.892621        0.904032
28             0.907869              0.892621        0.904032
30             0.907869              0.892621        0.904032
18             0.907869              0.892621        0.904032
24             0.907869              0.892621        0.904032
14             0.907869              0.892621        0.904032
12             0.907869              0.892621        0.904032
22             0.907869              0.892621        0.904032
16             0.907869              0.892621        0.904032
20             0.907869              0.892621        0.904032
10             0.907869              0.892621        0.904032
25             0.600328              0.000000        0.500000
49             0.600328              0.000000        0.500000
11             0.600328              0.000000        0.500000
53             0.600328              0.000000        0.500000
9              0.600328              0.000000        0.500000
13             0.600328              0.000000        0.500000
7              0.600328              0.000000        0.500000
55             0.600328              0.000000        0.500000
5              0.600328              0.000000        0.500000
57             0.600328              0.000000        0.500000
3              0.600328              0.000000        0.500000
47             0.600328              0.000000        0.500000
43             0.600328              0.000000        0.500000
45             0.600328              0.000000        0.500000
27             0.600328              0.000000        0.500000
15             0.600328              0.000000        0.500000
17             0.600328              0.000000        0.500000
39             0.600328              0.000000        0.500000
37             0.600328              0.000000        0.500000
19             0.600328              0.000000        0.500000
35             0.600328              0.000000        0.500000
33             0.600328              0.000000        0.500000
23             0.600328              0.000000        0.500000
1              0.600328              0.000000        0.500000
29             0.600328              0.000000        0.500000
59             0.600328              0.000000        0.500000
2023-05-26 07:39:29,137 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-26 07:39:29,179 [INFO] Save train_prediction_log data...
2023-05-26 07:39:29,183 [INFO] {'Data': 'train', 'ACC': '1.0 (607 / 608)', 'TP': 242, 'FP': 0, 'FN': 1, 'TN': 365, 'Precision': '1.0 (242 / 242 + 0)', 'Recall': '1.0 (242 / 242 + 1)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (365 / 365 + 0)', 'AUC': 1.0, 'r2': 0.99}
2023-05-26 07:39:29,195 [INFO] Save valid_prediction_log data...
2023-05-26 07:39:29,197 [INFO] {'Data': 'valid', 'ACC': '0.99 (151 / 152)', 'TP': 60, 'FP': 0, 'FN': 1, 'TN': 91, 'Precision': '1.0 (60 / 60 + 0)', 'Recall': '0.98 (60 / 60 + 1)', 'F1': '0.99 (2 * (0.98 * 1.0) / 0.98 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.99, 'r2': 0.97}
2023-05-26 07:39:29,219 [INFO] Save test_prediction_log data...
2023-05-26 07:39:29,222 [INFO] {'Data': 'test', 'ACC': '0.99 (150 / 151)', 'TP': 59, 'FP': 0, 'FN': 1, 'TN': 91, 'Precision': '1.0 (59 / 59 + 0)', 'Recall': '0.98 (59 / 59 + 1)', 'F1': '0.99 (2 * (0.98 * 1.0) / 0.98 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.99, 'r2': 0.97}
2023-05-26 07:39:29,236 [INFO] Save training_log data...
2023-05-26 07:39:29,238 [INFO] Save score_log data...
2023-05-26 07:39:29,238 [INFO] Time : 4.45601487159729
