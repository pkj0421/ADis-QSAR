2023-05-26 10:03:00,993 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_512bits\Standard\BTK_train_vector.tsv
2023-05-26 10:03:00,993 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_512bits\Standard\BTK_valid_vector.tsv
2023-05-26 10:03:00,993 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_512bits\Standard\BTK_model\SVM
2023-05-26 10:03:00,993 [INFO] Model type : SVM
2023-05-26 10:03:00,993 [INFO] Use cores : 12
2023-05-26 10:03:01,068 [INFO] Start Learning model
2023-05-26 10:03:01,068 [INFO] Train : 608 | Valid : 152
2023-05-26 10:03:01,068 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 10:03:15,237 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.906202              0.887300        0.903125
2              0.906202              0.887300        0.903125
4              0.906202              0.887300        0.903125
6              0.906202              0.887300        0.903125
8              0.906202              0.887300        0.903125
44             0.893087              0.865592        0.890692
28             0.893087              0.865592        0.890692
32             0.893087              0.865592        0.890692
34             0.893087              0.865592        0.890692
36             0.893087              0.865592        0.890692
38             0.893087              0.865592        0.890692
40             0.893087              0.865592        0.890692
42             0.893087              0.865592        0.890692
48             0.893087              0.865592        0.890692
46             0.893087              0.865592        0.890692
24             0.893087              0.865592        0.890692
50             0.893087              0.865592        0.890692
52             0.893087              0.865592        0.890692
54             0.893087              0.865592        0.890692
56             0.893087              0.865592        0.890692
58             0.893087              0.865592        0.890692
26             0.893087              0.865592        0.890692
30             0.893087              0.865592        0.890692
18             0.893087              0.865592        0.890692
10             0.893087              0.865592        0.890692
14             0.893087              0.865592        0.890692
22             0.893087              0.865592        0.890692
16             0.893087              0.865592        0.890692
12             0.893087              0.865592        0.890692
20             0.893087              0.865592        0.890692
31             0.628251              0.833333        0.536260
51             0.628251              0.833333        0.536260
41             0.628251              0.833333        0.536260
21             0.615109              0.650000        0.519111
5              0.600328              0.000000        0.500000
55             0.600328              0.000000        0.500000
7              0.600328              0.000000        0.500000
53             0.600328              0.000000        0.500000
45             0.600328              0.000000        0.500000
9              0.600328              0.000000        0.500000
57             0.600328              0.000000        0.500000
49             0.600328              0.000000        0.500000
11             0.600328              0.000000        0.500000
3              0.600328              0.000000        0.500000
47             0.600328              0.000000        0.500000
23             0.600328              0.000000        0.500000
13             0.600328              0.000000        0.500000
43             0.600328              0.000000        0.500000
15             0.600328              0.000000        0.500000
39             0.600328              0.000000        0.500000
37             0.600328              0.000000        0.500000
17             0.600328              0.000000        0.500000
35             0.600328              0.000000        0.500000
33             0.600328              0.000000        0.500000
19             0.600328              0.000000        0.500000
1              0.600328              0.000000        0.500000
29             0.600328              0.000000        0.500000
27             0.600328              0.000000        0.500000
25             0.600328              0.000000        0.500000
59             0.600328              0.000000        0.500000
2023-05-26 10:03:15,239 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-26 10:03:15,257 [INFO] Save train_prediction_log data...
2023-05-26 10:03:15,262 [INFO] {'Data': 'train', 'ACC': '1.0 (605 / 608)', 'TP': 241, 'FP': 1, 'FN': 2, 'TN': 364, 'Precision': '1.0 (241 / 241 + 1)', 'Recall': '0.99 (241 / 241 + 2)', 'F1': '0.99 (2 * (0.99 * 1.0) / 0.99 + 1.0)', 'Specificity': '1.0 (364 / 364 + 1)', 'AUC': 0.99, 'r2': 0.98}
2023-05-26 10:03:15,271 [INFO] Save valid_prediction_log data...
2023-05-26 10:03:15,273 [INFO] {'Data': 'valid', 'ACC': '0.98 (149 / 152)', 'TP': 59, 'FP': 1, 'FN': 2, 'TN': 90, 'Precision': '0.98 (59 / 59 + 1)', 'Recall': '0.97 (59 / 59 + 2)', 'F1': '0.97 (2 * (0.97 * 0.98) / 0.97 + 0.98)', 'Specificity': '0.99 (90 / 90 + 1)', 'AUC': 0.98, 'r2': 0.92}
2023-05-26 10:03:15,301 [INFO] Save test_prediction_log data...
2023-05-26 10:03:15,304 [INFO] {'Data': 'test', 'ACC': '0.99 (150 / 151)', 'TP': 60, 'FP': 1, 'FN': 0, 'TN': 90, 'Precision': '0.98 (60 / 60 + 1)', 'Recall': '1.0 (60 / 60 + 0)', 'F1': '0.99 (2 * (1.0 * 0.98) / 1.0 + 0.98)', 'Specificity': '0.99 (90 / 90 + 1)', 'AUC': 0.99, 'r2': 0.97}
2023-05-26 10:03:15,306 [INFO] Save training_log data...
2023-05-26 10:03:15,308 [INFO] Save score_log data...
2023-05-26 10:03:15,308 [INFO] Time : 14.314842939376831
