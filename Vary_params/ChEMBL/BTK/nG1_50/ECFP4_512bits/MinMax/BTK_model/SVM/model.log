2023-05-26 11:07:56,322 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_512bits\MinMax\BTK_train_vector.tsv
2023-05-26 11:07:56,322 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_512bits\MinMax\BTK_valid_vector.tsv
2023-05-26 11:07:56,322 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_50\ECFP4_512bits\MinMax\BTK_model\SVM
2023-05-26 11:07:56,323 [INFO] Model type : SVM
2023-05-26 11:07:56,323 [INFO] Use cores : 12
2023-05-26 11:07:56,360 [INFO] Start Learning model
2023-05-26 11:07:56,360 [INFO] Train : 608 | Valid : 152
2023-05-26 11:07:56,360 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 11:08:04,755 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
11             0.675929              1.000000        0.594583
23             0.735191              0.960556        0.670954
43             0.786175              0.954401        0.736863
53             0.786175              0.954401        0.736863
33             0.786175              0.954401        0.736863
21             0.934180              0.943739        0.927214
0              0.927623              0.936827        0.919779
2              0.927623              0.936827        0.919779
4              0.927623              0.936827        0.919779
6              0.927623              0.936827        0.919779
8              0.927623              0.936827        0.919779
31             0.932623              0.917249        0.930707
41             0.934235              0.916650        0.932707
51             0.934235              0.916650        0.932707
12             0.916066              0.899391        0.913513
18             0.916066              0.899391        0.913513
16             0.916066              0.899391        0.913513
10             0.916066              0.899391        0.913513
14             0.916066              0.899391        0.913513
50             0.907842              0.880534        0.905736
48             0.907842              0.880534        0.905736
46             0.907842              0.880534        0.905736
54             0.907842              0.880534        0.905736
52             0.907842              0.880534        0.905736
56             0.907842              0.880534        0.905736
58             0.907842              0.880534        0.905736
42             0.907842              0.880534        0.905736
40             0.907842              0.880534        0.905736
38             0.907842              0.880534        0.905736
36             0.907842              0.880534        0.905736
34             0.907842              0.880534        0.905736
44             0.907842              0.880534        0.905736
30             0.907842              0.880534        0.905736
32             0.907842              0.880534        0.905736
28             0.907842              0.880534        0.905736
22             0.907842              0.880534        0.905736
24             0.907842              0.880534        0.905736
26             0.907842              0.880534        0.905736
20             0.907842              0.880534        0.905736
39             0.600328              0.000000        0.500000
17             0.600328              0.000000        0.500000
3              0.600328              0.000000        0.500000
57             0.600328              0.000000        0.500000
5              0.600328              0.000000        0.500000
55             0.600328              0.000000        0.500000
7              0.600328              0.000000        0.500000
9              0.600328              0.000000        0.500000
13             0.600328              0.000000        0.500000
15             0.600328              0.000000        0.500000
49             0.600328              0.000000        0.500000
27             0.600328              0.000000        0.500000
19             0.600328              0.000000        0.500000
47             0.600328              0.000000        0.500000
1              0.600328              0.000000        0.500000
45             0.600328              0.000000        0.500000
35             0.600328              0.000000        0.500000
29             0.600328              0.000000        0.500000
25             0.600328              0.000000        0.500000
37             0.600328              0.000000        0.500000
59             0.600328              0.000000        0.500000
2023-05-26 11:08:04,756 [INFO] Best model :
SVC(C=0.1, gamma=0.01, random_state=42)
2023-05-26 11:08:04,817 [INFO] Save train_prediction_log data...
2023-05-26 11:08:04,822 [INFO] {'Data': 'train', 'ACC': '0.77 (469 / 608)', 'TP': 105, 'FP': 1, 'FN': 138, 'TN': 364, 'Precision': '0.99 (105 / 105 + 1)', 'Recall': '0.43 (105 / 105 + 138)', 'F1': '0.6 (2 * (0.43 * 0.99) / 0.43 + 0.99)', 'Specificity': '1.0 (364 / 364 + 1)', 'AUC': 0.71, 'r2': 0.05}
2023-05-26 11:08:04,840 [INFO] Save valid_prediction_log data...
2023-05-26 11:08:04,843 [INFO] {'Data': 'valid', 'ACC': '0.72 (110 / 152)', 'TP': 19, 'FP': 0, 'FN': 42, 'TN': 91, 'Precision': '1.0 (19 / 19 + 0)', 'Recall': '0.31 (19 / 19 + 42)', 'F1': '0.47 (2 * (0.31 * 1.0) / 0.31 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.66, 'r2': -0.15}
2023-05-26 11:08:04,872 [INFO] Save test_prediction_log data...
2023-05-26 11:08:04,875 [INFO] {'Data': 'test', 'ACC': '0.83 (126 / 151)', 'TP': 35, 'FP': 0, 'FN': 25, 'TN': 91, 'Precision': '1.0 (35 / 35 + 0)', 'Recall': '0.58 (35 / 35 + 25)', 'F1': '0.73 (2 * (0.58 * 1.0) / 0.58 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.79, 'r2': 0.31}
2023-05-26 11:08:04,878 [INFO] Save training_log data...
2023-05-26 11:08:04,879 [INFO] Save score_log data...
2023-05-26 11:08:04,880 [INFO] Time : 8.557777881622314
