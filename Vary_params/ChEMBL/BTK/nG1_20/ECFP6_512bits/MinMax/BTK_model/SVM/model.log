2023-05-26 06:30:11,022 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_20\ECFP6_512bits\MinMax\BTK_train_vector.tsv
2023-05-26 06:30:11,022 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_20\ECFP6_512bits\MinMax\BTK_valid_vector.tsv
2023-05-26 06:30:11,022 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_20\ECFP6_512bits\MinMax\BTK_model\SVM
2023-05-26 06:30:11,022 [INFO] Model type : SVM
2023-05-26 06:30:11,022 [INFO] Use cores : 12
2023-05-26 06:30:11,059 [INFO] Start Learning model
2023-05-26 06:30:11,059 [INFO] Train : 638 | Valid : 152
2023-05-26 06:30:11,059 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 06:30:19,362 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
11             0.674033              0.970833        0.619907
33             0.609648              0.950000        0.544350
53             0.609648              0.950000        0.544350
43             0.609648              0.950000        0.544350
0              0.920064              0.927790        0.915701
2              0.920064              0.927790        0.915701
4              0.920064              0.927790        0.915701
6              0.920064              0.927790        0.915701
8              0.920064              0.927790        0.915701
21             0.926314              0.925590        0.923506
51             0.929439              0.918896        0.928268
41             0.929439              0.918896        0.928268
31             0.929439              0.918896        0.928268
50             0.905903              0.905129        0.902436
28             0.905903              0.905129        0.902436
46             0.905903              0.905129        0.902436
44             0.905903              0.905129        0.902436
52             0.905903              0.905129        0.902436
42             0.905903              0.905129        0.902436
54             0.905903              0.905129        0.902436
40             0.905903              0.905129        0.902436
56             0.905903              0.905129        0.902436
38             0.905903              0.905129        0.902436
36             0.905903              0.905129        0.902436
34             0.905903              0.905129        0.902436
58             0.905903              0.905129        0.902436
32             0.905903              0.905129        0.902436
48             0.905903              0.905129        0.902436
30             0.905903              0.905129        0.902436
22             0.905903              0.905129        0.902436
26             0.905903              0.905129        0.902436
24             0.905903              0.905129        0.902436
20             0.905903              0.905129        0.902436
14             0.902803              0.900894        0.899403
12             0.902803              0.900894        0.899403
10             0.902803              0.900894        0.899403
18             0.902803              0.900894        0.899403
16             0.902803              0.900894        0.899403
23             0.583036              0.500000        0.512765
55             0.572098              0.000000        0.500000
7              0.572098              0.000000        0.500000
9              0.572098              0.000000        0.500000
5              0.572098              0.000000        0.500000
57             0.572098              0.000000        0.500000
3              0.572098              0.000000        0.500000
13             0.572098              0.000000        0.500000
49             0.572098              0.000000        0.500000
29             0.572098              0.000000        0.500000
47             0.572098              0.000000        0.500000
15             0.572098              0.000000        0.500000
45             0.572098              0.000000        0.500000
1              0.572098              0.000000        0.500000
17             0.572098              0.000000        0.500000
19             0.572098              0.000000        0.500000
39             0.572098              0.000000        0.500000
37             0.572098              0.000000        0.500000
35             0.572098              0.000000        0.500000
25             0.572098              0.000000        0.500000
27             0.572098              0.000000        0.500000
59             0.572098              0.000000        0.500000
2023-05-26 06:30:19,363 [INFO] Best model :
SVC(C=0.1, gamma=0.01, random_state=42)
2023-05-26 06:30:19,438 [INFO] Save train_prediction_log data...
2023-05-26 06:30:19,442 [INFO] {'Data': 'train', 'ACC': '0.79 (502 / 638)', 'TP': 140, 'FP': 3, 'FN': 133, 'TN': 362, 'Precision': '0.98 (140 / 140 + 3)', 'Recall': '0.51 (140 / 140 + 133)', 'F1': '0.67 (2 * (0.51 * 0.98) / 0.51 + 0.98)', 'Specificity': '0.99 (362 / 362 + 3)', 'AUC': 0.75, 'r2': 0.13}
2023-05-26 06:30:19,462 [INFO] Save valid_prediction_log data...
2023-05-26 06:30:19,465 [INFO] {'Data': 'valid', 'ACC': '0.8 (121 / 152)', 'TP': 31, 'FP': 1, 'FN': 30, 'TN': 90, 'Precision': '0.97 (31 / 31 + 1)', 'Recall': '0.51 (31 / 31 + 30)', 'F1': '0.67 (2 * (0.51 * 0.97) / 0.51 + 0.97)', 'Specificity': '0.99 (90 / 90 + 1)', 'AUC': 0.75, 'r2': 0.15}
2023-05-26 06:30:19,496 [INFO] Save test_prediction_log data...
2023-05-26 06:30:19,498 [INFO] {'Data': 'test', 'ACC': '0.86 (130 / 151)', 'TP': 42, 'FP': 3, 'FN': 18, 'TN': 88, 'Precision': '0.93 (42 / 42 + 3)', 'Recall': '0.7 (42 / 42 + 18)', 'F1': '0.8 (2 * (0.7 * 0.93) / 0.7 + 0.93)', 'Specificity': '0.97 (88 / 88 + 3)', 'AUC': 0.83, 'r2': 0.42}
2023-05-26 06:30:19,501 [INFO] Save training_log data...
2023-05-26 06:30:19,502 [INFO] Save score_log data...
2023-05-26 06:30:19,503 [INFO] Time : 8.481517791748047
