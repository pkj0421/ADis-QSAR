2023-05-26 05:34:44,936 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_20\ECFP6_512bits\Standard\BTK_train_vector.tsv
2023-05-26 05:34:44,937 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_20\ECFP6_512bits\Standard\BTK_valid_vector.tsv
2023-05-26 05:34:44,937 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_20\ECFP6_512bits\Standard\BTK_model\SVM
2023-05-26 05:34:44,937 [INFO] Model type : SVM
2023-05-26 05:34:44,937 [INFO] Use cores : 12
2023-05-26 05:34:45,004 [INFO] Start Learning model
2023-05-26 05:34:45,005 [INFO] Train : 638 | Valid : 152
2023-05-26 05:34:45,005 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 05:34:53,968 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
31             0.628472              0.970909        0.566638
51             0.628472              0.970909        0.566638
41             0.628472              0.970909        0.566638
0              0.901265              0.902798        0.897192
2              0.901265              0.902798        0.897192
4              0.901265              0.902798        0.897192
6              0.901265              0.902798        0.897192
8              0.901265              0.902798        0.897192
42             0.899653              0.898600        0.895737
32             0.899653              0.898600        0.895737
34             0.899653              0.898600        0.895737
36             0.899653              0.898600        0.895737
38             0.899653              0.898600        0.895737
40             0.899653              0.898600        0.895737
48             0.899653              0.898600        0.895737
44             0.899653              0.898600        0.895737
46             0.899653              0.898600        0.895737
26             0.899653              0.898600        0.895737
50             0.899653              0.898600        0.895737
52             0.899653              0.898600        0.895737
54             0.899653              0.898600        0.895737
56             0.899653              0.898600        0.895737
58             0.899653              0.898600        0.895737
28             0.899653              0.898600        0.895737
30             0.899653              0.898600        0.895737
10             0.899653              0.898600        0.895737
14             0.899653              0.898600        0.895737
12             0.899653              0.898600        0.895737
24             0.899653              0.898600        0.895737
16             0.899653              0.898600        0.895737
22             0.899653              0.898600        0.895737
20             0.899653              0.898600        0.895737
18             0.899653              0.898600        0.895737
21             0.587723              0.700000        0.518188
25             0.572098              0.000000        0.500000
49             0.572098              0.000000        0.500000
11             0.572098              0.000000        0.500000
53             0.572098              0.000000        0.500000
9              0.572098              0.000000        0.500000
13             0.572098              0.000000        0.500000
7              0.572098              0.000000        0.500000
55             0.572098              0.000000        0.500000
5              0.572098              0.000000        0.500000
57             0.572098              0.000000        0.500000
3              0.572098              0.000000        0.500000
47             0.572098              0.000000        0.500000
15             0.572098              0.000000        0.500000
45             0.572098              0.000000        0.500000
43             0.572098              0.000000        0.500000
17             0.572098              0.000000        0.500000
39             0.572098              0.000000        0.500000
37             0.572098              0.000000        0.500000
19             0.572098              0.000000        0.500000
35             0.572098              0.000000        0.500000
33             0.572098              0.000000        0.500000
1              0.572098              0.000000        0.500000
29             0.572098              0.000000        0.500000
23             0.572098              0.000000        0.500000
27             0.572098              0.000000        0.500000
59             0.572098              0.000000        0.500000
2023-05-26 05:34:53,970 [INFO] Best model :
SVC(C=10, gamma=0.01, random_state=42)
2023-05-26 05:34:54,384 [INFO] Save train_prediction_log data...
2023-05-26 05:34:54,388 [INFO] {'Data': 'train', 'ACC': '1.0 (638 / 638)', 'TP': 273, 'FP': 0, 'FN': 0, 'TN': 365, 'Precision': '1.0 (273 / 273 + 0)', 'Recall': '1.0 (273 / 273 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (365 / 365 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-26 05:34:54,411 [INFO] Save valid_prediction_log data...
2023-05-26 05:34:54,413 [INFO] {'Data': 'valid', 'ACC': '0.66 (100 / 152)', 'TP': 9, 'FP': 0, 'FN': 52, 'TN': 91, 'Precision': '1.0 (9 / 9 + 0)', 'Recall': '0.15 (9 / 9 + 52)', 'F1': '0.26 (2 * (0.15 * 1.0) / 0.15 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.57, 'r2': -0.42}
2023-05-26 05:34:54,455 [INFO] Save test_prediction_log data...
2023-05-26 05:34:54,458 [INFO] {'Data': 'test', 'ACC': '0.7 (106 / 151)', 'TP': 15, 'FP': 0, 'FN': 45, 'TN': 91, 'Precision': '1.0 (15 / 15 + 0)', 'Recall': '0.25 (15 / 15 + 45)', 'F1': '0.4 (2 * (0.25 * 1.0) / 0.25 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.62, 'r2': -0.24}
2023-05-26 05:34:54,461 [INFO] Save training_log data...
2023-05-26 05:34:54,463 [INFO] Save score_log data...
2023-05-26 05:34:54,464 [INFO] Time : 9.527854919433594
