2023-05-26 01:02:58,691 [INFO] Train data : Vary_params\ChEMBL\BTK\nG1_20\ECFP4_512bits\Standard\BTK_train_vector.tsv
2023-05-26 01:02:58,691 [INFO] Valid data : Vary_params\ChEMBL\BTK\nG1_20\ECFP4_512bits\Standard\BTK_valid_vector.tsv
2023-05-26 01:02:58,691 [INFO] Output path : Vary_params\ChEMBL\BTK\nG1_20\ECFP4_512bits\Standard\BTK_model\SVM
2023-05-26 01:02:58,691 [INFO] Model type : SVM
2023-05-26 01:02:58,691 [INFO] Use cores : 12
2023-05-26 01:02:58,759 [INFO] Start Learning model
2023-05-26 01:02:58,759 [INFO] Train : 638 | Valid : 152
2023-05-26 01:02:58,759 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 01:03:08,664 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.628447              0.988889        0.566071
31             0.659797              0.975000        0.603212
51             0.659797              0.975000        0.603212
41             0.659797              0.975000        0.603212
0              0.901215              0.882800        0.900526
2              0.901215              0.882800        0.900526
4              0.901215              0.882800        0.900526
6              0.901215              0.882800        0.900526
8              0.901215              0.882800        0.900526
42             0.899653              0.878731        0.898901
32             0.899653              0.878731        0.898901
34             0.899653              0.878731        0.898901
36             0.899653              0.878731        0.898901
38             0.899653              0.878731        0.898901
40             0.899653              0.878731        0.898901
48             0.899653              0.878731        0.898901
44             0.899653              0.878731        0.898901
46             0.899653              0.878731        0.898901
26             0.899653              0.878731        0.898901
50             0.899653              0.878731        0.898901
52             0.899653              0.878731        0.898901
54             0.899653              0.878731        0.898901
56             0.899653              0.878731        0.898901
58             0.899653              0.878731        0.898901
28             0.899653              0.878731        0.898901
30             0.899653              0.878731        0.898901
18             0.899653              0.878731        0.898901
24             0.899653              0.878731        0.898901
14             0.899653              0.878731        0.898901
12             0.899653              0.878731        0.898901
22             0.899653              0.878731        0.898901
16             0.899653              0.878731        0.898901
20             0.899653              0.878731        0.898901
10             0.899653              0.878731        0.898901
25             0.572098              0.000000        0.500000
49             0.572098              0.000000        0.500000
11             0.572098              0.000000        0.500000
53             0.572098              0.000000        0.500000
9              0.572098              0.000000        0.500000
13             0.572098              0.000000        0.500000
7              0.572098              0.000000        0.500000
55             0.572098              0.000000        0.500000
5              0.572098              0.000000        0.500000
57             0.572098              0.000000        0.500000
3              0.572098              0.000000        0.500000
47             0.572098              0.000000        0.500000
43             0.572098              0.000000        0.500000
45             0.572098              0.000000        0.500000
27             0.572098              0.000000        0.500000
15             0.572098              0.000000        0.500000
17             0.572098              0.000000        0.500000
39             0.572098              0.000000        0.500000
37             0.572098              0.000000        0.500000
19             0.572098              0.000000        0.500000
35             0.572098              0.000000        0.500000
33             0.572098              0.000000        0.500000
23             0.572098              0.000000        0.500000
1              0.572098              0.000000        0.500000
29             0.572098              0.000000        0.500000
59             0.572098              0.000000        0.500000
2023-05-26 01:03:08,664 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-26 01:03:08,743 [INFO] Save train_prediction_log data...
2023-05-26 01:03:08,747 [INFO] {'Data': 'train', 'ACC': '1.0 (638 / 638)', 'TP': 273, 'FP': 0, 'FN': 0, 'TN': 365, 'Precision': '1.0 (273 / 273 + 0)', 'Recall': '1.0 (273 / 273 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (365 / 365 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-26 01:03:08,769 [INFO] Save valid_prediction_log data...
2023-05-26 01:03:08,772 [INFO] {'Data': 'valid', 'ACC': '0.68 (104 / 152)', 'TP': 13, 'FP': 0, 'FN': 48, 'TN': 91, 'Precision': '1.0 (13 / 13 + 0)', 'Recall': '0.21 (13 / 13 + 48)', 'F1': '0.35 (2 * (0.21 * 1.0) / 0.21 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.61, 'r2': -0.31}
2023-05-26 01:03:08,810 [INFO] Save test_prediction_log data...
2023-05-26 01:03:08,813 [INFO] {'Data': 'test', 'ACC': '0.69 (104 / 151)', 'TP': 13, 'FP': 0, 'FN': 47, 'TN': 91, 'Precision': '1.0 (13 / 13 + 0)', 'Recall': '0.22 (13 / 13 + 47)', 'F1': '0.36 (2 * (0.22 * 1.0) / 0.22 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.61, 'r2': -0.3}
2023-05-26 01:03:08,815 [INFO] Save training_log data...
2023-05-26 01:03:08,817 [INFO] Save score_log data...
2023-05-26 01:03:08,818 [INFO] Time : 10.126704692840576
