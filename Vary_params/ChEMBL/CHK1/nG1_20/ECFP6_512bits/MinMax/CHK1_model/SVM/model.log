2023-05-27 12:36:37,839 [INFO] Train data : Vary_params\ChEMBL\CHK1\nG1_20\ECFP6_512bits\MinMax\CHK1_train_vector.tsv
2023-05-27 12:36:37,839 [INFO] Valid data : Vary_params\ChEMBL\CHK1\nG1_20\ECFP6_512bits\MinMax\CHK1_valid_vector.tsv
2023-05-27 12:36:37,839 [INFO] Output path : Vary_params\ChEMBL\CHK1\nG1_20\ECFP6_512bits\MinMax\CHK1_model\SVM
2023-05-27 12:36:37,839 [INFO] Model type : SVM
2023-05-27 12:36:37,839 [INFO] Use cores : 12
2023-05-27 12:36:37,882 [INFO] Start Learning model
2023-05-27 12:36:37,882 [INFO] Train : 865 | Valid : 209
2023-05-27 12:36:37,882 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 12:37:00,506 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
11             0.699532              1.000000        0.642980
53             0.724886              0.957195        0.675583
43             0.724886              0.957195        0.675583
33             0.724886              0.957195        0.675583
23             0.690217              0.946984        0.634366
21             0.933093              0.945106        0.928287
31             0.939989              0.932830        0.938635
41             0.937690              0.928874        0.936635
51             0.937690              0.928874        0.936635
0              0.921505              0.926995        0.916826
6              0.921505              0.926995        0.916826
2              0.921505              0.926995        0.916826
4              0.921505              0.926995        0.916826
8              0.921505              0.926995        0.916826
10             0.913446              0.892132        0.913861
18             0.913446              0.892132        0.913861
16             0.913446              0.892132        0.913861
14             0.913446              0.892132        0.913861
12             0.913446              0.892132        0.913861
50             0.892609              0.877611        0.890511
54             0.892609              0.877611        0.890511
48             0.892609              0.877611        0.890511
46             0.892609              0.877611        0.890511
44             0.892609              0.877611        0.890511
52             0.892609              0.877611        0.890511
58             0.892609              0.877611        0.890511
42             0.892609              0.877611        0.890511
40             0.892609              0.877611        0.890511
38             0.892609              0.877611        0.890511
36             0.892609              0.877611        0.890511
34             0.892609              0.877611        0.890511
56             0.892609              0.877611        0.890511
30             0.892609              0.877611        0.890511
32             0.892609              0.877611        0.890511
28             0.892609              0.877611        0.890511
22             0.892609              0.877611        0.890511
24             0.892609              0.877611        0.890511
26             0.892609              0.877611        0.890511
20             0.892609              0.877611        0.890511
39             0.579203              0.000000        0.500000
17             0.579203              0.000000        0.500000
3              0.579203              0.000000        0.500000
57             0.579203              0.000000        0.500000
5              0.579203              0.000000        0.500000
55             0.579203              0.000000        0.500000
7              0.579203              0.000000        0.500000
9              0.579203              0.000000        0.500000
13             0.579203              0.000000        0.500000
15             0.579203              0.000000        0.500000
49             0.579203              0.000000        0.500000
27             0.579203              0.000000        0.500000
19             0.579203              0.000000        0.500000
47             0.579203              0.000000        0.500000
1              0.579203              0.000000        0.500000
45             0.579203              0.000000        0.500000
35             0.579203              0.000000        0.500000
29             0.579203              0.000000        0.500000
25             0.579203              0.000000        0.500000
37             0.579203              0.000000        0.500000
59             0.579203              0.000000        0.500000
2023-05-27 12:37:00,507 [INFO] Best model :
SVC(C=0.1, gamma=0.01, random_state=42)
2023-05-27 12:37:00,626 [INFO] Save train_prediction_log data...
2023-05-27 12:37:00,643 [INFO] {'Data': 'train', 'ACC': '0.76 (657 / 865)', 'TP': 156, 'FP': 0, 'FN': 208, 'TN': 501, 'Precision': '1.0 (156 / 156 + 0)', 'Recall': '0.43 (156 / 156 + 208)', 'F1': '0.6 (2 * (0.43 * 1.0) / 0.43 + 1.0)', 'Specificity': '1.0 (501 / 501 + 0)', 'AUC': 0.71, 'r2': 0.01}
2023-05-27 12:37:00,674 [INFO] Save valid_prediction_log data...
2023-05-27 12:37:00,677 [INFO] {'Data': 'valid', 'ACC': '0.79 (165 / 209)', 'TP': 40, 'FP': 0, 'FN': 44, 'TN': 125, 'Precision': '1.0 (40 / 40 + 0)', 'Recall': '0.48 (40 / 40 + 44)', 'F1': '0.65 (2 * (0.48 * 1.0) / 0.48 + 1.0)', 'Specificity': '1.0 (125 / 125 + 0)', 'AUC': 0.74, 'r2': 0.12}
2023-05-27 12:37:00,727 [INFO] Save test_prediction_log data...
2023-05-27 12:37:00,730 [INFO] {'Data': 'test', 'ACC': '0.8 (167 / 209)', 'TP': 41, 'FP': 0, 'FN': 42, 'TN': 126, 'Precision': '1.0 (41 / 41 + 0)', 'Recall': '0.49 (41 / 41 + 42)', 'F1': '0.66 (2 * (0.49 * 1.0) / 0.49 + 1.0)', 'Specificity': '1.0 (126 / 126 + 0)', 'AUC': 0.75, 'r2': 0.16}
2023-05-27 12:37:00,734 [INFO] Save training_log data...
2023-05-27 12:37:00,737 [INFO] Save score_log data...
2023-05-27 12:37:00,738 [INFO] Time : 22.899188995361328
