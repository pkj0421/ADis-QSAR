2023-05-28 08:07:15,845 [INFO] Train data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP6_256bits\Standard\CHK1_train_vector.tsv
2023-05-28 08:07:15,845 [INFO] Valid data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP6_256bits\Standard\CHK1_valid_vector.tsv
2023-05-28 08:07:15,845 [INFO] Output path : Vary_params\ChEMBL\CHK1\nG1_80\ECFP6_256bits\Standard\CHK1_model\SVM
2023-05-28 08:07:15,845 [INFO] Model type : SVM
2023-05-28 08:07:15,845 [INFO] Use cores : 12
2023-05-28 08:07:15,889 [INFO] Start Learning model
2023-05-28 08:07:15,889 [INFO] Train : 805 | Valid : 209
2023-05-28 08:07:15,889 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 08:07:22,333 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
41             0.909414              0.956764        0.888398
31             0.909414              0.956764        0.888398
51             0.909414              0.956764        0.888398
21             0.897022              0.954295        0.872000
0              0.901944              0.900149        0.890654
2              0.901944              0.900149        0.890654
4              0.901944              0.900149        0.890654
6              0.901944              0.900149        0.890654
8              0.901944              0.900149        0.890654
12             0.870910              0.826540        0.865840
18             0.870910              0.826540        0.865840
16             0.870910              0.826540        0.865840
14             0.870910              0.826540        0.865840
10             0.870910              0.826540        0.865840
50             0.860957              0.806014        0.857786
48             0.860957              0.806014        0.857786
52             0.860957              0.806014        0.857786
46             0.860957              0.806014        0.857786
54             0.860957              0.806014        0.857786
44             0.860957              0.806014        0.857786
42             0.860957              0.806014        0.857786
56             0.860957              0.806014        0.857786
58             0.860957              0.806014        0.857786
40             0.860957              0.806014        0.857786
38             0.860957              0.806014        0.857786
36             0.860957              0.806014        0.857786
34             0.860957              0.806014        0.857786
32             0.860957              0.806014        0.857786
30             0.860957              0.806014        0.857786
24             0.860957              0.806014        0.857786
28             0.860957              0.806014        0.857786
26             0.860957              0.806014        0.857786
20             0.860957              0.806014        0.857786
22             0.860957              0.806014        0.857786
53             0.622377              0.000000        0.500000
49             0.622377              0.000000        0.500000
13             0.622377              0.000000        0.500000
11             0.622377              0.000000        0.500000
9              0.622377              0.000000        0.500000
29             0.622377              0.000000        0.500000
47             0.622377              0.000000        0.500000
7              0.622377              0.000000        0.500000
55             0.622377              0.000000        0.500000
5              0.622377              0.000000        0.500000
57             0.622377              0.000000        0.500000
3              0.622377              0.000000        0.500000
15             0.622377              0.000000        0.500000
19             0.622377              0.000000        0.500000
17             0.622377              0.000000        0.500000
45             0.622377              0.000000        0.500000
1              0.622377              0.000000        0.500000
43             0.622377              0.000000        0.500000
23             0.622377              0.000000        0.500000
39             0.622377              0.000000        0.500000
37             0.622377              0.000000        0.500000
25             0.622377              0.000000        0.500000
35             0.622377              0.000000        0.500000
33             0.622377              0.000000        0.500000
27             0.622377              0.000000        0.500000
59             0.622377              0.000000        0.500000
2023-05-28 08:07:22,334 [INFO] Best model :
SVC(C=10, gamma=0.01, random_state=42)
2023-05-28 08:07:22,412 [INFO] Save train_prediction_log data...
2023-05-28 08:07:22,416 [INFO] {'Data': 'train', 'ACC': '1.0 (805 / 805)', 'TP': 304, 'FP': 0, 'FN': 0, 'TN': 501, 'Precision': '1.0 (304 / 304 + 0)', 'Recall': '1.0 (304 / 304 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (501 / 501 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 08:07:22,438 [INFO] Save valid_prediction_log data...
2023-05-28 08:07:22,441 [INFO] {'Data': 'valid', 'ACC': '0.94 (197 / 209)', 'TP': 74, 'FP': 2, 'FN': 10, 'TN': 123, 'Precision': '0.97 (74 / 74 + 2)', 'Recall': '0.88 (74 / 74 + 10)', 'F1': '0.92 (2 * (0.88 * 0.97) / 0.88 + 0.97)', 'Specificity': '0.98 (123 / 123 + 2)', 'AUC': 0.93, 'r2': 0.76}
2023-05-28 08:07:22,474 [INFO] Save test_prediction_log data...
2023-05-28 08:07:22,476 [INFO] {'Data': 'test', 'ACC': '0.99 (206 / 209)', 'TP': 82, 'FP': 2, 'FN': 1, 'TN': 124, 'Precision': '0.98 (82 / 82 + 2)', 'Recall': '0.99 (82 / 82 + 1)', 'F1': '0.98 (2 * (0.99 * 0.98) / 0.99 + 0.98)', 'Specificity': '0.98 (124 / 124 + 2)', 'AUC': 0.99, 'r2': 0.94}
2023-05-28 08:07:22,486 [INFO] Save training_log data...
2023-05-28 08:07:22,487 [INFO] Save score_log data...
2023-05-28 08:07:22,488 [INFO] Time : 6.643283128738403
