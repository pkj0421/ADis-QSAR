2023-05-28 02:50:27,011 [INFO] Train data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_256bits\MinMax\CHK1_train_vector.tsv
2023-05-28 02:50:27,011 [INFO] Valid data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_256bits\MinMax\CHK1_valid_vector.tsv
2023-05-28 02:50:27,011 [INFO] Output path : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_256bits\MinMax\CHK1_model\SVM
2023-05-28 02:50:27,011 [INFO] Model type : SVM
2023-05-28 02:50:27,011 [INFO] Use cores : 12
2023-05-28 02:50:27,034 [INFO] Start Learning model
2023-05-28 02:50:27,034 [INFO] Train : 805 | Valid : 209
2023-05-28 02:50:27,034 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 02:50:33,207 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
23             0.894506              0.958287        0.867387
43             0.903194              0.954667        0.880118
33             0.903194              0.954667        0.880118
53             0.903194              0.954667        0.880118
21             0.914383              0.932574        0.900183
31             0.933071              0.917202        0.929385
8              0.893225              0.913798        0.874839
0              0.893225              0.913798        0.874839
2              0.893225              0.913798        0.874839
6              0.893225              0.913798        0.874839
4              0.893225              0.913798        0.874839
51             0.930571              0.912303        0.927331
41             0.930571              0.912303        0.927331
11             0.668364              0.900000        0.560753
16             0.913164              0.886291        0.910233
10             0.913164              0.886291        0.910233
12             0.913164              0.886291        0.910233
14             0.913164              0.886291        0.910233
18             0.913164              0.886291        0.910233
34             0.887022              0.839758        0.885184
36             0.887022              0.839758        0.885184
38             0.887022              0.839758        0.885184
40             0.887022              0.839758        0.885184
42             0.887022              0.839758        0.885184
54             0.887022              0.839758        0.885184
58             0.887022              0.839758        0.885184
44             0.887022              0.839758        0.885184
48             0.887022              0.839758        0.885184
50             0.887022              0.839758        0.885184
56             0.887022              0.839758        0.885184
52             0.887022              0.839758        0.885184
46             0.887022              0.839758        0.885184
30             0.887022              0.839758        0.885184
32             0.887022              0.839758        0.885184
28             0.879599              0.829817        0.877380
22             0.879599              0.829817        0.877380
24             0.879599              0.829817        0.877380
26             0.879599              0.829817        0.877380
20             0.879599              0.829817        0.877380
39             0.622377              0.000000        0.500000
17             0.622377              0.000000        0.500000
3              0.622377              0.000000        0.500000
57             0.622377              0.000000        0.500000
5              0.622377              0.000000        0.500000
55             0.622377              0.000000        0.500000
7              0.622377              0.000000        0.500000
9              0.622377              0.000000        0.500000
13             0.622377              0.000000        0.500000
15             0.622377              0.000000        0.500000
49             0.622377              0.000000        0.500000
27             0.622377              0.000000        0.500000
19             0.622377              0.000000        0.500000
47             0.622377              0.000000        0.500000
1              0.622377              0.000000        0.500000
45             0.622377              0.000000        0.500000
35             0.622377              0.000000        0.500000
29             0.622377              0.000000        0.500000
25             0.622377              0.000000        0.500000
37             0.622377              0.000000        0.500000
59             0.622377              0.000000        0.500000
2023-05-28 02:50:33,209 [INFO] Best model :
SVC(C=1, gamma=0.1, random_state=42)
2023-05-28 02:50:33,284 [INFO] Save train_prediction_log data...
2023-05-28 02:50:33,289 [INFO] {'Data': 'train', 'ACC': '1.0 (805 / 805)', 'TP': 304, 'FP': 0, 'FN': 0, 'TN': 501, 'Precision': '1.0 (304 / 304 + 0)', 'Recall': '1.0 (304 / 304 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (501 / 501 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 02:50:33,310 [INFO] Save valid_prediction_log data...
2023-05-28 02:50:33,313 [INFO] {'Data': 'valid', 'ACC': '0.91 (191 / 209)', 'TP': 68, 'FP': 2, 'FN': 16, 'TN': 123, 'Precision': '0.97 (68 / 68 + 2)', 'Recall': '0.81 (68 / 68 + 16)', 'F1': '0.88 (2 * (0.81 * 0.97) / 0.81 + 0.97)', 'Specificity': '0.98 (123 / 123 + 2)', 'AUC': 0.9, 'r2': 0.64}
2023-05-28 02:50:33,342 [INFO] Save test_prediction_log data...
2023-05-28 02:50:33,344 [INFO] {'Data': 'test', 'ACC': '0.97 (202 / 209)', 'TP': 78, 'FP': 2, 'FN': 5, 'TN': 124, 'Precision': '0.98 (78 / 78 + 2)', 'Recall': '0.94 (78 / 78 + 5)', 'F1': '0.96 (2 * (0.94 * 0.98) / 0.94 + 0.98)', 'Specificity': '0.98 (124 / 124 + 2)', 'AUC': 0.96, 'r2': 0.86}
2023-05-28 02:50:33,347 [INFO] Save training_log data...
2023-05-28 02:50:33,348 [INFO] Save score_log data...
2023-05-28 02:50:33,349 [INFO] Time : 6.337151288986206
