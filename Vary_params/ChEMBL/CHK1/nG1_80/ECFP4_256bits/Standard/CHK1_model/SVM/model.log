2023-05-28 02:12:43,342 [INFO] Train data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_256bits\Standard\CHK1_train_vector.tsv
2023-05-28 02:12:43,342 [INFO] Valid data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_256bits\Standard\CHK1_valid_vector.tsv
2023-05-28 02:12:43,342 [INFO] Output path : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_256bits\Standard\CHK1_model\SVM
2023-05-28 02:12:43,342 [INFO] Model type : SVM
2023-05-28 02:12:43,342 [INFO] Use cores : 12
2023-05-28 02:12:43,386 [INFO] Start Learning model
2023-05-28 02:12:43,386 [INFO] Train : 805 | Valid : 209
2023-05-28 02:12:43,386 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 02:12:49,658 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.900694              0.961104        0.875505
31             0.910679              0.955668        0.890065
51             0.910679              0.955668        0.890065
41             0.910679              0.955668        0.890065
0              0.908210              0.882223        0.903727
2              0.908210              0.882223        0.903727
4              0.908210              0.882223        0.903727
6              0.908210              0.882223        0.903727
8              0.908210              0.882223        0.903727
42             0.879630              0.833836        0.876698
32             0.879630              0.833836        0.876698
34             0.879630              0.833836        0.876698
36             0.879630              0.833836        0.876698
38             0.879630              0.833836        0.876698
40             0.879630              0.833836        0.876698
48             0.879630              0.833836        0.876698
44             0.879630              0.833836        0.876698
46             0.879630              0.833836        0.876698
26             0.879630              0.833836        0.876698
50             0.879630              0.833836        0.876698
52             0.879630              0.833836        0.876698
54             0.879630              0.833836        0.876698
56             0.879630              0.833836        0.876698
58             0.879630              0.833836        0.876698
28             0.879630              0.833836        0.876698
30             0.879630              0.833836        0.876698
24             0.879630              0.833836        0.876698
22             0.879630              0.833836        0.876698
20             0.879630              0.833836        0.876698
18             0.872160              0.822445        0.869414
14             0.872160              0.822445        0.869414
12             0.872160              0.822445        0.869414
16             0.872160              0.822445        0.869414
10             0.872160              0.822445        0.869414
25             0.622377              0.000000        0.500000
49             0.622377              0.000000        0.500000
11             0.622377              0.000000        0.500000
53             0.622377              0.000000        0.500000
9              0.622377              0.000000        0.500000
13             0.622377              0.000000        0.500000
7              0.622377              0.000000        0.500000
55             0.622377              0.000000        0.500000
5              0.622377              0.000000        0.500000
57             0.622377              0.000000        0.500000
3              0.622377              0.000000        0.500000
47             0.622377              0.000000        0.500000
43             0.622377              0.000000        0.500000
45             0.622377              0.000000        0.500000
27             0.622377              0.000000        0.500000
15             0.622377              0.000000        0.500000
17             0.622377              0.000000        0.500000
39             0.622377              0.000000        0.500000
37             0.622377              0.000000        0.500000
19             0.622377              0.000000        0.500000
35             0.622377              0.000000        0.500000
33             0.622377              0.000000        0.500000
23             0.622377              0.000000        0.500000
1              0.622377              0.000000        0.500000
29             0.622377              0.000000        0.500000
59             0.622377              0.000000        0.500000
2023-05-28 02:12:49,659 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-28 02:12:49,733 [INFO] Save train_prediction_log data...
2023-05-28 02:12:49,737 [INFO] {'Data': 'train', 'ACC': '1.0 (805 / 805)', 'TP': 304, 'FP': 0, 'FN': 0, 'TN': 501, 'Precision': '1.0 (304 / 304 + 0)', 'Recall': '1.0 (304 / 304 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (501 / 501 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 02:12:49,758 [INFO] Save valid_prediction_log data...
2023-05-28 02:12:49,769 [INFO] {'Data': 'valid', 'ACC': '0.92 (192 / 209)', 'TP': 69, 'FP': 2, 'FN': 15, 'TN': 123, 'Precision': '0.97 (69 / 69 + 2)', 'Recall': '0.82 (69 / 69 + 15)', 'F1': '0.89 (2 * (0.82 * 0.97) / 0.82 + 0.97)', 'Specificity': '0.98 (123 / 123 + 2)', 'AUC': 0.9, 'r2': 0.66}
2023-05-28 02:12:49,800 [INFO] Save test_prediction_log data...
2023-05-28 02:12:49,803 [INFO] {'Data': 'test', 'ACC': '0.97 (202 / 209)', 'TP': 78, 'FP': 2, 'FN': 5, 'TN': 124, 'Precision': '0.98 (78 / 78 + 2)', 'Recall': '0.94 (78 / 78 + 5)', 'F1': '0.96 (2 * (0.94 * 0.98) / 0.94 + 0.98)', 'Specificity': '0.98 (124 / 124 + 2)', 'AUC': 0.96, 'r2': 0.86}
2023-05-28 02:12:49,805 [INFO] Save training_log data...
2023-05-28 02:12:49,806 [INFO] Save score_log data...
2023-05-28 02:12:49,807 [INFO] Time : 6.466385126113892
