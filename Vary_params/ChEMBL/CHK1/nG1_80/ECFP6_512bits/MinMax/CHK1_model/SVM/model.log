2023-05-28 12:25:02,958 [INFO] Train data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP6_512bits\MinMax\CHK1_train_vector.tsv
2023-05-28 12:25:02,958 [INFO] Valid data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP6_512bits\MinMax\CHK1_valid_vector.tsv
2023-05-28 12:25:02,958 [INFO] Output path : Vary_params\ChEMBL\CHK1\nG1_80\ECFP6_512bits\MinMax\CHK1_model\SVM
2023-05-28 12:25:02,958 [INFO] Model type : SVM
2023-05-28 12:25:02,958 [INFO] Use cores : 12
2023-05-28 12:25:03,000 [INFO] Start Learning model
2023-05-28 12:25:03,001 [INFO] Train : 805 | Valid : 209
2023-05-28 12:25:03,001 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 12:25:20,260 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
23             0.657083              1.000000        0.545914
11             0.678241              1.000000        0.573763
21             0.928086              0.945064        0.915688
43             0.689460              0.933214        0.591989
53             0.689460              0.933214        0.591989
33             0.689460              0.933214        0.591989
0              0.919398              0.925959        0.908095
2              0.919398              0.925959        0.908095
4              0.919398              0.925959        0.908095
6              0.919398              0.925959        0.908095
8              0.919398              0.925959        0.908095
51             0.936790              0.916807        0.934837
41             0.936790              0.916807        0.934837
31             0.935556              0.916052        0.933224
14             0.918164              0.883136        0.917405
18             0.918164              0.883136        0.917405
10             0.918164              0.883136        0.917405
16             0.918164              0.883136        0.917405
12             0.918164              0.883136        0.917405
50             0.908194              0.874124        0.906631
48             0.908194              0.874124        0.906631
46             0.908194              0.874124        0.906631
44             0.908194              0.874124        0.906631
52             0.908194              0.874124        0.906631
56             0.908194              0.874124        0.906631
42             0.908194              0.874124        0.906631
58             0.908194              0.874124        0.906631
40             0.908194              0.874124        0.906631
38             0.908194              0.874124        0.906631
36             0.908194              0.874124        0.906631
34             0.908194              0.874124        0.906631
54             0.908194              0.874124        0.906631
30             0.908194              0.874124        0.906631
32             0.908194              0.874124        0.906631
28             0.908194              0.874124        0.906631
22             0.908194              0.874124        0.906631
24             0.908194              0.874124        0.906631
26             0.908194              0.874124        0.906631
20             0.908194              0.874124        0.906631
39             0.622377              0.000000        0.500000
17             0.622377              0.000000        0.500000
3              0.622377              0.000000        0.500000
57             0.622377              0.000000        0.500000
5              0.622377              0.000000        0.500000
55             0.622377              0.000000        0.500000
7              0.622377              0.000000        0.500000
9              0.622377              0.000000        0.500000
13             0.622377              0.000000        0.500000
15             0.622377              0.000000        0.500000
49             0.622377              0.000000        0.500000
27             0.622377              0.000000        0.500000
19             0.622377              0.000000        0.500000
47             0.622377              0.000000        0.500000
1              0.622377              0.000000        0.500000
45             0.622377              0.000000        0.500000
35             0.622377              0.000000        0.500000
29             0.622377              0.000000        0.500000
25             0.622377              0.000000        0.500000
37             0.622377              0.000000        0.500000
59             0.622377              0.000000        0.500000
2023-05-28 12:25:20,261 [INFO] Best model :
SVC(C=0.1, gamma=0.01, random_state=42)
2023-05-28 12:25:20,363 [INFO] Save train_prediction_log data...
2023-05-28 12:25:20,367 [INFO] {'Data': 'train', 'ACC': '0.72 (580 / 805)', 'TP': 79, 'FP': 0, 'FN': 225, 'TN': 501, 'Precision': '1.0 (79 / 79 + 0)', 'Recall': '0.26 (79 / 79 + 225)', 'F1': '0.41 (2 * (0.26 * 1.0) / 0.26 + 1.0)', 'Specificity': '1.0 (501 / 501 + 0)', 'AUC': 0.63, 'r2': -0.19}
2023-05-28 12:25:20,395 [INFO] Save valid_prediction_log data...
2023-05-28 12:25:20,397 [INFO] {'Data': 'valid', 'ACC': '0.72 (150 / 209)', 'TP': 25, 'FP': 0, 'FN': 59, 'TN': 125, 'Precision': '1.0 (25 / 25 + 0)', 'Recall': '0.3 (25 / 25 + 59)', 'F1': '0.46 (2 * (0.3 * 1.0) / 0.3 + 1.0)', 'Specificity': '1.0 (125 / 125 + 0)', 'AUC': 0.65, 'r2': -0.17}
2023-05-28 12:25:20,438 [INFO] Save test_prediction_log data...
2023-05-28 12:25:20,452 [INFO] {'Data': 'test', 'ACC': '0.72 (151 / 209)', 'TP': 25, 'FP': 0, 'FN': 58, 'TN': 126, 'Precision': '1.0 (25 / 25 + 0)', 'Recall': '0.3 (25 / 25 + 58)', 'F1': '0.46 (2 * (0.3 * 1.0) / 0.3 + 1.0)', 'Specificity': '1.0 (126 / 126 + 0)', 'AUC': 0.65, 'r2': -0.16}
2023-05-28 12:25:20,454 [INFO] Save training_log data...
2023-05-28 12:25:20,456 [INFO] Save score_log data...
2023-05-28 12:25:20,457 [INFO] Time : 17.498966693878174
