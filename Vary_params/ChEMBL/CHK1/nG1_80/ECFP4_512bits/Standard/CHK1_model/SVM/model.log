2023-05-28 05:15:16,276 [INFO] Train data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_512bits\Standard\CHK1_train_vector.tsv
2023-05-28 05:15:16,276 [INFO] Valid data : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_512bits\Standard\CHK1_valid_vector.tsv
2023-05-28 05:15:16,276 [INFO] Output path : Vary_params\ChEMBL\CHK1\nG1_80\ECFP4_512bits\Standard\CHK1_model\SVM
2023-05-28 05:15:16,276 [INFO] Model type : SVM
2023-05-28 05:15:16,276 [INFO] Use cores : 12
2023-05-28 05:15:16,362 [INFO] Start Learning model
2023-05-28 05:15:16,363 [INFO] Train : 805 | Valid : 209
2023-05-28 05:15:16,363 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 05:15:35,234 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.690664              0.987500        0.590935
41             0.725448              0.972106        0.638129
31             0.725448              0.972106        0.638129
51             0.725448              0.972106        0.638129
0              0.914460              0.890483        0.911704
2              0.914460              0.890483        0.911704
4              0.914460              0.890483        0.911704
6              0.914460              0.890483        0.911704
8              0.914460              0.890483        0.911704
12             0.898318              0.865640        0.895478
18             0.898318              0.865640        0.895478
16             0.898318              0.865640        0.895478
14             0.898318              0.865640        0.895478
10             0.898318              0.865640        0.895478
50             0.898318              0.863860        0.895552
48             0.898318              0.863860        0.895552
52             0.898318              0.863860        0.895552
46             0.898318              0.863860        0.895552
54             0.898318              0.863860        0.895552
44             0.898318              0.863860        0.895552
42             0.898318              0.863860        0.895552
56             0.898318              0.863860        0.895552
58             0.898318              0.863860        0.895552
40             0.898318              0.863860        0.895552
38             0.898318              0.863860        0.895552
36             0.898318              0.863860        0.895552
34             0.898318              0.863860        0.895552
32             0.898318              0.863860        0.895552
30             0.898318              0.863860        0.895552
24             0.898318              0.863860        0.895552
28             0.898318              0.863860        0.895552
26             0.898318              0.863860        0.895552
20             0.898318              0.863860        0.895552
22             0.898318              0.863860        0.895552
53             0.622377              0.000000        0.500000
49             0.622377              0.000000        0.500000
13             0.622377              0.000000        0.500000
11             0.622377              0.000000        0.500000
9              0.622377              0.000000        0.500000
29             0.622377              0.000000        0.500000
47             0.622377              0.000000        0.500000
7              0.622377              0.000000        0.500000
55             0.622377              0.000000        0.500000
5              0.622377              0.000000        0.500000
57             0.622377              0.000000        0.500000
3              0.622377              0.000000        0.500000
15             0.622377              0.000000        0.500000
19             0.622377              0.000000        0.500000
17             0.622377              0.000000        0.500000
45             0.622377              0.000000        0.500000
1              0.622377              0.000000        0.500000
43             0.622377              0.000000        0.500000
23             0.622377              0.000000        0.500000
39             0.622377              0.000000        0.500000
37             0.622377              0.000000        0.500000
25             0.622377              0.000000        0.500000
35             0.622377              0.000000        0.500000
33             0.622377              0.000000        0.500000
27             0.622377              0.000000        0.500000
59             0.622377              0.000000        0.500000
2023-05-28 05:15:35,236 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-28 05:15:35,357 [INFO] Save train_prediction_log data...
2023-05-28 05:15:35,362 [INFO] {'Data': 'train', 'ACC': '1.0 (805 / 805)', 'TP': 304, 'FP': 0, 'FN': 0, 'TN': 501, 'Precision': '1.0 (304 / 304 + 0)', 'Recall': '1.0 (304 / 304 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (501 / 501 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 05:15:35,395 [INFO] Save valid_prediction_log data...
2023-05-28 05:15:35,398 [INFO] {'Data': 'valid', 'ACC': '0.72 (151 / 209)', 'TP': 26, 'FP': 0, 'FN': 58, 'TN': 125, 'Precision': '1.0 (26 / 26 + 0)', 'Recall': '0.31 (26 / 26 + 58)', 'F1': '0.47 (2 * (0.31 * 1.0) / 0.31 + 1.0)', 'Specificity': '1.0 (125 / 125 + 0)', 'AUC': 0.65, 'r2': -0.15}
2023-05-28 05:15:35,457 [INFO] Save test_prediction_log data...
2023-05-28 05:15:35,470 [INFO] {'Data': 'test', 'ACC': '0.77 (161 / 209)', 'TP': 36, 'FP': 1, 'FN': 47, 'TN': 125, 'Precision': '0.97 (36 / 36 + 1)', 'Recall': '0.43 (36 / 36 + 47)', 'F1': '0.6 (2 * (0.43 * 0.97) / 0.43 + 0.97)', 'Specificity': '0.99 (125 / 125 + 1)', 'AUC': 0.71, 'r2': 0.04}
2023-05-28 05:15:35,474 [INFO] Save training_log data...
2023-05-28 05:15:35,475 [INFO] Save score_log data...
2023-05-28 05:15:35,476 [INFO] Time : 19.19986581802368
