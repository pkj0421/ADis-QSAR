2023-05-27 15:38:37,192 [INFO] Train data : Vary_params\ChEMBL\PIM1\nG1_80\ECFP6_512bits\Standard\PIM1_train_vector.tsv
2023-05-27 15:38:37,192 [INFO] Valid data : Vary_params\ChEMBL\PIM1\nG1_80\ECFP6_512bits\Standard\PIM1_valid_vector.tsv
2023-05-27 15:38:37,192 [INFO] Output path : Vary_params\ChEMBL\PIM1\nG1_80\ECFP6_512bits\Standard\PIM1_model\SVM
2023-05-27 15:38:37,192 [INFO] Model type : SVM
2023-05-27 15:38:37,193 [INFO] Use cores : 17
2023-05-27 15:38:37,273 [INFO] Start Learning model
2023-05-27 15:38:37,273 [INFO] Train : 500 | Valid : 133
2023-05-27 15:38:37,273 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 15:38:44,337 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0                 0.902              0.870954        0.893096
2                 0.902              0.870954        0.893096
4                 0.902              0.870954        0.893096
6                 0.902              0.870954        0.893096
8                 0.902              0.870954        0.893096
44                0.898              0.869563        0.888655
28                0.898              0.869563        0.888655
32                0.898              0.869563        0.888655
34                0.898              0.869563        0.888655
36                0.898              0.869563        0.888655
38                0.898              0.869563        0.888655
40                0.898              0.869563        0.888655
42                0.898              0.869563        0.888655
48                0.898              0.869563        0.888655
46                0.898              0.869563        0.888655
24                0.898              0.869563        0.888655
50                0.898              0.869563        0.888655
52                0.898              0.869563        0.888655
54                0.898              0.869563        0.888655
56                0.898              0.869563        0.888655
58                0.898              0.869563        0.888655
26                0.898              0.869563        0.888655
30                0.898              0.869563        0.888655
12                0.898              0.869563        0.888655
18                0.898              0.869563        0.888655
14                0.898              0.869563        0.888655
22                0.898              0.869563        0.888655
16                0.898              0.869563        0.888655
20                0.898              0.869563        0.888655
10                0.898              0.869563        0.888655
51                0.640              0.200000        0.505409
41                0.640              0.200000        0.505409
31                0.640              0.200000        0.505409
53                0.636              0.000000        0.500000
45                0.636              0.000000        0.500000
7                 0.636              0.000000        0.500000
55                0.636              0.000000        0.500000
49                0.636              0.000000        0.500000
5                 0.636              0.000000        0.500000
11                0.636              0.000000        0.500000
47                0.636              0.000000        0.500000
57                0.636              0.000000        0.500000
3                 0.636              0.000000        0.500000
9                 0.636              0.000000        0.500000
23                0.636              0.000000        0.500000
13                0.636              0.000000        0.500000
43                0.636              0.000000        0.500000
15                0.636              0.000000        0.500000
39                0.636              0.000000        0.500000
37                0.636              0.000000        0.500000
17                0.636              0.000000        0.500000
35                0.636              0.000000        0.500000
33                0.636              0.000000        0.500000
19                0.636              0.000000        0.500000
1                 0.636              0.000000        0.500000
29                0.636              0.000000        0.500000
27                0.636              0.000000        0.500000
21                0.636              0.000000        0.500000
25                0.636              0.000000        0.500000
59                0.636              0.000000        0.500000
2023-05-27 15:38:44,338 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-27 15:38:44,367 [INFO] Save train_prediction_log data...
2023-05-27 15:38:44,371 [INFO] {'Data': 'train', 'ACC': '1.0 (500 / 500)', 'TP': 182, 'FP': 0, 'FN': 0, 'TN': 318, 'Precision': '1.0 (182 / 182 + 0)', 'Recall': '1.0 (182 / 182 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (318 / 318 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 15:38:44,380 [INFO] Save valid_prediction_log data...
2023-05-27 15:38:44,383 [INFO] {'Data': 'valid', 'ACC': '0.95 (127 / 133)', 'TP': 48, 'FP': 1, 'FN': 5, 'TN': 79, 'Precision': '0.98 (48 / 48 + 1)', 'Recall': '0.91 (48 / 48 + 5)', 'F1': '0.94 (2 * (0.91 * 0.98) / 0.91 + 0.98)', 'Specificity': '0.99 (79 / 79 + 1)', 'AUC': 0.95, 'r2': 0.81}
2023-05-27 15:38:44,412 [INFO] Save test_prediction_log data...
2023-05-27 15:38:44,415 [INFO] {'Data': 'test', 'ACC': '0.98 (129 / 132)', 'TP': 51, 'FP': 1, 'FN': 2, 'TN': 78, 'Precision': '0.98 (51 / 51 + 1)', 'Recall': '0.96 (51 / 51 + 2)', 'F1': '0.97 (2 * (0.96 * 0.98) / 0.96 + 0.98)', 'Specificity': '0.99 (78 / 78 + 1)', 'AUC': 0.97, 'r2': 0.91}
2023-05-27 15:38:44,417 [INFO] Save training_log data...
2023-05-27 15:38:44,419 [INFO] Save score_log data...
2023-05-27 15:38:44,420 [INFO] Time : 7.228062629699707
