2023-05-27 07:56:45,779 [INFO] Train data : Vary_params\ChEMBL\HGF\nG1_50\ECFP4_512bits\MinMax\HGF_train_vector.tsv
2023-05-27 07:56:45,779 [INFO] Valid data : Vary_params\ChEMBL\HGF\nG1_50\ECFP4_512bits\MinMax\HGF_valid_vector.tsv
2023-05-27 07:56:45,779 [INFO] Output path : Vary_params\ChEMBL\HGF\nG1_50\ECFP4_512bits\MinMax\HGF_model\SVM
2023-05-27 07:56:45,779 [INFO] Model type : SVM
2023-05-27 07:56:45,779 [INFO] Use cores : 11
2023-05-27 07:56:45,821 [INFO] Start Learning model
2023-05-27 07:56:45,821 [INFO] Train : 853 | Valid : 213
2023-05-27 07:56:45,821 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 07:56:59,209 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
11             0.672955              0.970833        0.591947
23             0.791300              0.961920        0.742484
43             0.814761              0.950468        0.773324
53             0.814761              0.950468        0.773324
33             0.814761              0.950468        0.773324
21             0.905062              0.926222        0.892998
0              0.875746              0.913222        0.857297
2              0.875746              0.913222        0.857297
4              0.875746              0.913222        0.857297
6              0.875746              0.913222        0.857297
8              0.875746              0.913222        0.857297
51             0.918003              0.903195        0.914949
41             0.918003              0.903195        0.914949
31             0.915650              0.899998        0.912498
14             0.901518              0.886398        0.896322
18             0.901518              0.886398        0.896322
10             0.901518              0.886398        0.896322
16             0.901518              0.886398        0.896322
12             0.901518              0.886398        0.896322
50             0.875705              0.846927        0.870524
48             0.875705              0.846927        0.870524
46             0.875705              0.846927        0.870524
44             0.875705              0.846927        0.870524
52             0.875705              0.846927        0.870524
56             0.875705              0.846927        0.870524
42             0.875705              0.846927        0.870524
58             0.875705              0.846927        0.870524
40             0.875705              0.846927        0.870524
38             0.875705              0.846927        0.870524
36             0.875705              0.846927        0.870524
34             0.875705              0.846927        0.870524
54             0.875705              0.846927        0.870524
30             0.875705              0.846927        0.870524
32             0.875705              0.846927        0.870524
28             0.875705              0.846927        0.870524
22             0.875705              0.846927        0.870524
24             0.875705              0.846927        0.870524
26             0.875705              0.846927        0.870524
20             0.875705              0.846927        0.870524
39             0.600233              0.000000        0.500000
17             0.600233              0.000000        0.500000
3              0.600233              0.000000        0.500000
57             0.600233              0.000000        0.500000
5              0.600233              0.000000        0.500000
55             0.600233              0.000000        0.500000
7              0.600233              0.000000        0.500000
9              0.600233              0.000000        0.500000
13             0.600233              0.000000        0.500000
15             0.600233              0.000000        0.500000
49             0.600233              0.000000        0.500000
27             0.600233              0.000000        0.500000
19             0.600233              0.000000        0.500000
47             0.600233              0.000000        0.500000
1              0.600233              0.000000        0.500000
45             0.600233              0.000000        0.500000
35             0.600233              0.000000        0.500000
29             0.600233              0.000000        0.500000
25             0.600233              0.000000        0.500000
37             0.600233              0.000000        0.500000
59             0.600233              0.000000        0.500000
2023-05-27 07:56:59,210 [INFO] Best model :
SVC(C=0.1, gamma=0.01, random_state=42)
2023-05-27 07:56:59,309 [INFO] Save train_prediction_log data...
2023-05-27 07:56:59,313 [INFO] {'Data': 'train', 'ACC': '0.76 (647 / 853)', 'TP': 137, 'FP': 2, 'FN': 204, 'TN': 510, 'Precision': '0.99 (137 / 137 + 2)', 'Recall': '0.4 (137 / 137 + 204)', 'F1': '0.57 (2 * (0.4 * 0.99) / 0.4 + 0.99)', 'Specificity': '1.0 (510 / 510 + 2)', 'AUC': 0.7, 'r2': -0.01}
2023-05-27 07:56:59,342 [INFO] Save valid_prediction_log data...
2023-05-27 07:56:59,344 [INFO] {'Data': 'valid', 'ACC': '0.76 (161 / 213)', 'TP': 34, 'FP': 1, 'FN': 51, 'TN': 127, 'Precision': '0.97 (34 / 34 + 1)', 'Recall': '0.4 (34 / 34 + 51)', 'F1': '0.57 (2 * (0.4 * 0.97) / 0.4 + 0.97)', 'Specificity': '0.99 (127 / 127 + 1)', 'AUC': 0.7, 'r2': -0.02}
2023-05-27 07:56:59,383 [INFO] Save test_prediction_log data...
2023-05-27 07:56:59,386 [INFO] {'Data': 'test', 'ACC': '0.86 (184 / 214)', 'TP': 56, 'FP': 0, 'FN': 30, 'TN': 128, 'Precision': '1.0 (56 / 56 + 0)', 'Recall': '0.65 (56 / 56 + 30)', 'F1': '0.79 (2 * (0.65 * 1.0) / 0.65 + 1.0)', 'Specificity': '1.0 (128 / 128 + 0)', 'AUC': 0.83, 'r2': 0.42}
2023-05-27 07:56:59,388 [INFO] Save training_log data...
2023-05-27 07:56:59,389 [INFO] Save score_log data...
2023-05-27 07:56:59,390 [INFO] Time : 13.610885620117188
