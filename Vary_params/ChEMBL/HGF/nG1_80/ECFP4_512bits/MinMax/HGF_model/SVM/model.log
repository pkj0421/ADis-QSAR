2023-05-27 19:13:35,988 [INFO] Train data : Vary_params\ChEMBL\HGF\nG1_80\ECFP4_512bits\MinMax\HGF_train_vector.tsv
2023-05-27 19:13:35,988 [INFO] Valid data : Vary_params\ChEMBL\HGF\nG1_80\ECFP4_512bits\MinMax\HGF_valid_vector.tsv
2023-05-27 19:13:35,988 [INFO] Output path : Vary_params\ChEMBL\HGF\nG1_80\ECFP4_512bits\MinMax\HGF_model\SVM
2023-05-27 19:13:35,988 [INFO] Model type : SVM
2023-05-27 19:13:35,988 [INFO] Use cores : 11
2023-05-27 19:13:36,025 [INFO] Start Learning model
2023-05-27 19:13:36,025 [INFO] Train : 823 | Valid : 213
2023-05-27 19:13:36,025 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 19:13:47,567 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
23             0.746033              0.973889        0.666240
11             0.648854              0.966667        0.536016
43             0.786086              0.958146        0.721332
53             0.786086              0.958146        0.721332
33             0.786086              0.958146        0.721332
21             0.906509              0.930609        0.888467
0              0.881017              0.911886        0.857227
2              0.881017              0.911886        0.857227
4              0.881017              0.911886        0.857227
6              0.881017              0.911886        0.857227
8              0.881017              0.911886        0.857227
51             0.932089              0.907492        0.929695
41             0.932089              0.907492        0.929695
31             0.930870              0.904158        0.928714
14             0.895548              0.861106        0.890219
18             0.895548              0.861106        0.890219
10             0.895548              0.861106        0.890219
16             0.895548              0.861106        0.890219
12             0.895548              0.861106        0.890219
50             0.893138              0.852566        0.889505
48             0.893138              0.852566        0.889505
46             0.893138              0.852566        0.889505
44             0.893138              0.852566        0.889505
52             0.893138              0.852566        0.889505
56             0.893138              0.852566        0.889505
42             0.893138              0.852566        0.889505
58             0.893138              0.852566        0.889505
40             0.893138              0.852566        0.889505
38             0.893138              0.852566        0.889505
36             0.893138              0.852566        0.889505
34             0.893138              0.852566        0.889505
54             0.893138              0.852566        0.889505
30             0.893138              0.852566        0.889505
32             0.893138              0.852566        0.889505
28             0.893138              0.852566        0.889505
22             0.893138              0.852566        0.889505
24             0.893138              0.852566        0.889505
26             0.893138              0.852566        0.889505
20             0.893138              0.852566        0.889505
39             0.622113              0.000000        0.500000
17             0.622113              0.000000        0.500000
3              0.622113              0.000000        0.500000
57             0.622113              0.000000        0.500000
5              0.622113              0.000000        0.500000
55             0.622113              0.000000        0.500000
7              0.622113              0.000000        0.500000
9              0.622113              0.000000        0.500000
13             0.622113              0.000000        0.500000
15             0.622113              0.000000        0.500000
49             0.622113              0.000000        0.500000
27             0.622113              0.000000        0.500000
19             0.622113              0.000000        0.500000
47             0.622113              0.000000        0.500000
1              0.622113              0.000000        0.500000
45             0.622113              0.000000        0.500000
35             0.622113              0.000000        0.500000
29             0.622113              0.000000        0.500000
25             0.622113              0.000000        0.500000
37             0.622113              0.000000        0.500000
59             0.622113              0.000000        0.500000
2023-05-27 19:13:47,569 [INFO] Best model :
SVC(C=1, gamma=0.1, random_state=42)
2023-05-27 19:13:47,684 [INFO] Save train_prediction_log data...
2023-05-27 19:13:47,688 [INFO] {'Data': 'train', 'ACC': '1.0 (823 / 823)', 'TP': 311, 'FP': 0, 'FN': 0, 'TN': 512, 'Precision': '1.0 (311 / 311 + 0)', 'Recall': '1.0 (311 / 311 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (512 / 512 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 19:13:47,720 [INFO] Save valid_prediction_log data...
2023-05-27 19:13:47,722 [INFO] {'Data': 'valid', 'ACC': '0.86 (183 / 213)', 'TP': 55, 'FP': 0, 'FN': 30, 'TN': 128, 'Precision': '1.0 (55 / 55 + 0)', 'Recall': '0.65 (55 / 55 + 30)', 'F1': '0.79 (2 * (0.65 * 1.0) / 0.65 + 1.0)', 'Specificity': '1.0 (128 / 128 + 0)', 'AUC': 0.82, 'r2': 0.41}
2023-05-27 19:13:47,767 [INFO] Save test_prediction_log data...
2023-05-27 19:13:47,769 [INFO] {'Data': 'test', 'ACC': '0.92 (196 / 214)', 'TP': 68, 'FP': 0, 'FN': 18, 'TN': 128, 'Precision': '1.0 (68 / 68 + 0)', 'Recall': '0.79 (68 / 68 + 18)', 'F1': '0.88 (2 * (0.79 * 1.0) / 0.79 + 1.0)', 'Specificity': '1.0 (128 / 128 + 0)', 'AUC': 0.9, 'r2': 0.65}
2023-05-27 19:13:47,772 [INFO] Save training_log data...
2023-05-27 19:13:47,773 [INFO] Save score_log data...
2023-05-27 19:13:47,774 [INFO] Time : 11.786120414733887
