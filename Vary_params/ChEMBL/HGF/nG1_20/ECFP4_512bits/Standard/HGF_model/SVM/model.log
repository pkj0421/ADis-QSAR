2023-05-26 19:19:47,845 [INFO] Train data : Vary_params\ChEMBL\HGF\nG1_20\ECFP4_512bits\Standard\HGF_train_vector.tsv
2023-05-26 19:19:47,845 [INFO] Valid data : Vary_params\ChEMBL\HGF\nG1_20\ECFP4_512bits\Standard\HGF_valid_vector.tsv
2023-05-26 19:19:47,845 [INFO] Output path : Vary_params\ChEMBL\HGF\nG1_20\ECFP4_512bits\Standard\HGF_model\SVM
2023-05-26 19:19:47,845 [INFO] Model type : SVM
2023-05-26 19:19:47,845 [INFO] Use cores : 11
2023-05-26 19:19:47,934 [INFO] Start Learning model
2023-05-26 19:19:47,934 [INFO] Train : 883 | Valid : 213
2023-05-26 19:19:47,934 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 19:20:02,294 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
31             0.685074              0.987500        0.625478
51             0.685074              0.987500        0.625478
41             0.685074              0.987500        0.625478
21             0.637577              0.980000        0.569041
0              0.903728              0.875090        0.903620
2              0.903728              0.875090        0.903620
4              0.903728              0.875090        0.903620
6              0.903728              0.875090        0.903620
8              0.903728              0.875090        0.903620
42             0.895787              0.870231        0.894531
32             0.895787              0.870231        0.894531
34             0.895787              0.870231        0.894531
36             0.895787              0.870231        0.894531
38             0.895787              0.870231        0.894531
40             0.895787              0.870231        0.894531
48             0.895787              0.870231        0.894531
44             0.895787              0.870231        0.894531
46             0.895787              0.870231        0.894531
26             0.895787              0.870231        0.894531
50             0.895787              0.870231        0.894531
52             0.895787              0.870231        0.894531
54             0.895787              0.870231        0.894531
56             0.895787              0.870231        0.894531
58             0.895787              0.870231        0.894531
28             0.895787              0.870231        0.894531
30             0.895787              0.870231        0.894531
18             0.895787              0.870231        0.894531
24             0.895787              0.870231        0.894531
14             0.895787              0.870231        0.894531
12             0.895787              0.870231        0.894531
22             0.895787              0.870231        0.894531
16             0.895787              0.870231        0.894531
20             0.895787              0.870231        0.894531
10             0.895787              0.870231        0.894531
25             0.579839              0.000000        0.500000
49             0.579839              0.000000        0.500000
11             0.579839              0.000000        0.500000
53             0.579839              0.000000        0.500000
9              0.579839              0.000000        0.500000
13             0.579839              0.000000        0.500000
7              0.579839              0.000000        0.500000
55             0.579839              0.000000        0.500000
5              0.579839              0.000000        0.500000
57             0.579839              0.000000        0.500000
3              0.579839              0.000000        0.500000
47             0.579839              0.000000        0.500000
43             0.579839              0.000000        0.500000
45             0.579839              0.000000        0.500000
27             0.579839              0.000000        0.500000
15             0.579839              0.000000        0.500000
17             0.579839              0.000000        0.500000
39             0.579839              0.000000        0.500000
37             0.579839              0.000000        0.500000
19             0.579839              0.000000        0.500000
35             0.579839              0.000000        0.500000
33             0.579839              0.000000        0.500000
23             0.579839              0.000000        0.500000
1              0.579839              0.000000        0.500000
29             0.579839              0.000000        0.500000
59             0.579839              0.000000        0.500000
2023-05-26 19:20:02,296 [INFO] Best model :
SVC(C=10, gamma=0.01, random_state=42)
2023-05-26 19:20:02,427 [INFO] Save train_prediction_log data...
2023-05-26 19:20:02,431 [INFO] {'Data': 'train', 'ACC': '1.0 (883 / 883)', 'TP': 371, 'FP': 0, 'FN': 0, 'TN': 512, 'Precision': '1.0 (371 / 371 + 0)', 'Recall': '1.0 (371 / 371 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (512 / 512 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-26 19:20:02,464 [INFO] Save valid_prediction_log data...
2023-05-26 19:20:02,466 [INFO] {'Data': 'valid', 'ACC': '0.75 (159 / 213)', 'TP': 32, 'FP': 1, 'FN': 53, 'TN': 127, 'Precision': '0.97 (32 / 32 + 1)', 'Recall': '0.38 (32 / 32 + 53)', 'F1': '0.55 (2 * (0.38 * 0.97) / 0.38 + 0.97)', 'Specificity': '0.99 (127 / 127 + 1)', 'AUC': 0.68, 'r2': -0.06}
2023-05-26 19:20:02,520 [INFO] Save test_prediction_log data...
2023-05-26 19:20:02,522 [INFO] {'Data': 'test', 'ACC': '0.74 (159 / 214)', 'TP': 31, 'FP': 0, 'FN': 55, 'TN': 128, 'Precision': '1.0 (31 / 31 + 0)', 'Recall': '0.36 (31 / 31 + 55)', 'F1': '0.53 (2 * (0.36 * 1.0) / 0.36 + 1.0)', 'Specificity': '1.0 (128 / 128 + 0)', 'AUC': 0.68, 'r2': -0.07}
2023-05-26 19:20:02,525 [INFO] Save training_log data...
2023-05-26 19:20:02,526 [INFO] Save score_log data...
2023-05-26 19:20:02,527 [INFO] Time : 14.682108640670776
