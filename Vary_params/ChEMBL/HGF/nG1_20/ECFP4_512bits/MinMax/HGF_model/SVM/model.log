2023-05-26 20:28:40,093 [INFO] Train data : Vary_params\ChEMBL\HGF\nG1_20\ECFP4_512bits\MinMax\HGF_train_vector.tsv
2023-05-26 20:28:40,093 [INFO] Valid data : Vary_params\ChEMBL\HGF\nG1_20\ECFP4_512bits\MinMax\HGF_valid_vector.tsv
2023-05-26 20:28:40,093 [INFO] Output path : Vary_params\ChEMBL\HGF\nG1_20\ECFP4_512bits\MinMax\HGF_model\SVM
2023-05-26 20:28:40,093 [INFO] Model type : SVM
2023-05-26 20:28:40,093 [INFO] Use cores : 11
2023-05-26 20:28:40,135 [INFO] Start Learning model
2023-05-26 20:28:40,135 [INFO] Train : 883 | Valid : 213
2023-05-26 20:28:40,135 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 20:28:53,892 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
11             0.722625              0.962778        0.671805
23             0.851634              0.957306        0.827906
43             0.866382              0.951867        0.846234
53             0.866382              0.951867        0.846234
33             0.866382              0.951867        0.846234
21             0.903843              0.921208        0.896253
0              0.873251              0.908887        0.860315
2              0.873251              0.908887        0.860315
4              0.873251              0.908887        0.860315
6              0.873251              0.908887        0.860315
8              0.873251              0.908887        0.860315
51             0.928741              0.905003        0.929533
41             0.928741              0.905003        0.929533
31             0.928728              0.904235        0.929533
14             0.902656              0.874075        0.903012
18             0.902656              0.874075        0.903012
10             0.902656              0.874075        0.903012
16             0.902656              0.874075        0.903012
12             0.902656              0.874075        0.903012
50             0.893501              0.854809        0.894780
48             0.893501              0.854809        0.894780
46             0.893501              0.854809        0.894780
44             0.893501              0.854809        0.894780
52             0.893501              0.854809        0.894780
56             0.893501              0.854809        0.894780
42             0.893501              0.854809        0.894780
58             0.893501              0.854809        0.894780
40             0.893501              0.854809        0.894780
38             0.893501              0.854809        0.894780
36             0.893501              0.854809        0.894780
34             0.893501              0.854809        0.894780
54             0.893501              0.854809        0.894780
30             0.893501              0.854809        0.894780
32             0.893501              0.854809        0.894780
28             0.893501              0.854809        0.894780
22             0.893501              0.854809        0.894780
24             0.893501              0.854809        0.894780
26             0.893501              0.854809        0.894780
20             0.893501              0.854809        0.894780
39             0.579839              0.000000        0.500000
17             0.579839              0.000000        0.500000
3              0.579839              0.000000        0.500000
57             0.579839              0.000000        0.500000
5              0.579839              0.000000        0.500000
55             0.579839              0.000000        0.500000
7              0.579839              0.000000        0.500000
9              0.579839              0.000000        0.500000
13             0.579839              0.000000        0.500000
15             0.579839              0.000000        0.500000
49             0.579839              0.000000        0.500000
27             0.579839              0.000000        0.500000
19             0.579839              0.000000        0.500000
47             0.579839              0.000000        0.500000
1              0.579839              0.000000        0.500000
45             0.579839              0.000000        0.500000
35             0.579839              0.000000        0.500000
29             0.579839              0.000000        0.500000
25             0.579839              0.000000        0.500000
37             0.579839              0.000000        0.500000
59             0.579839              0.000000        0.500000
2023-05-26 20:28:53,894 [INFO] Best model :
SVC(C=0.1, gamma=0.01, random_state=42)
2023-05-26 20:28:54,007 [INFO] Save train_prediction_log data...
2023-05-26 20:28:54,011 [INFO] {'Data': 'train', 'ACC': '0.8 (706 / 883)', 'TP': 200, 'FP': 6, 'FN': 171, 'TN': 506, 'Precision': '0.97 (200 / 200 + 6)', 'Recall': '0.54 (200 / 200 + 171)', 'F1': '0.69 (2 * (0.54 * 0.97) / 0.54 + 0.97)', 'Specificity': '0.99 (506 / 506 + 6)', 'AUC': 0.76, 'r2': 0.18}
2023-05-26 20:28:54,041 [INFO] Save valid_prediction_log data...
2023-05-26 20:28:54,043 [INFO] {'Data': 'valid', 'ACC': '0.81 (173 / 213)', 'TP': 50, 'FP': 5, 'FN': 35, 'TN': 123, 'Precision': '0.91 (50 / 50 + 5)', 'Recall': '0.59 (50 / 50 + 35)', 'F1': '0.72 (2 * (0.59 * 0.91) / 0.59 + 0.91)', 'Specificity': '0.96 (123 / 123 + 5)', 'AUC': 0.77, 'r2': 0.22}
2023-05-26 20:28:54,085 [INFO] Save test_prediction_log data...
2023-05-26 20:28:54,087 [INFO] {'Data': 'test', 'ACC': '0.89 (190 / 214)', 'TP': 69, 'FP': 7, 'FN': 17, 'TN': 121, 'Precision': '0.91 (69 / 69 + 7)', 'Recall': '0.8 (69 / 69 + 17)', 'F1': '0.85 (2 * (0.8 * 0.91) / 0.8 + 0.91)', 'Specificity': '0.95 (121 / 121 + 7)', 'AUC': 0.87, 'r2': 0.53}
2023-05-26 20:28:54,090 [INFO] Save training_log data...
2023-05-26 20:28:54,091 [INFO] Save score_log data...
2023-05-26 20:28:54,092 [INFO] Time : 13.99931526184082
