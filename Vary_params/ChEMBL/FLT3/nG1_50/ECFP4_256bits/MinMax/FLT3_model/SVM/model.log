2023-05-27 00:54:22,516 [INFO] Train data : Vary_params\ChEMBL\FLT3\nG1_50\ECFP4_256bits\MinMax\FLT3_train_vector.tsv
2023-05-27 00:54:22,516 [INFO] Valid data : Vary_params\ChEMBL\FLT3\nG1_50\ECFP4_256bits\MinMax\FLT3_valid_vector.tsv
2023-05-27 00:54:22,516 [INFO] Output path : Vary_params\ChEMBL\FLT3\nG1_50\ECFP4_256bits\MinMax\FLT3_model\SVM
2023-05-27 00:54:22,516 [INFO] Model type : SVM
2023-05-27 00:54:22,516 [INFO] Use cores : 18
2023-05-27 00:54:22,533 [INFO] Start Learning model
2023-05-27 00:54:22,533 [INFO] Train : 650 | Valid : 163
2023-05-27 00:54:22,533 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 00:54:26,517 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
23             0.727692              0.935556        0.662821
33             0.749231              0.904304        0.693590
53             0.749231              0.904304        0.693590
43             0.749231              0.904304        0.693590
31             0.827692              0.792849        0.821795
41             0.826154              0.791934        0.819872
51             0.826154              0.791934        0.819872
21             0.786154              0.787906        0.764744
0              0.752308              0.762211        0.722436
2              0.752308              0.762211        0.722436
4              0.752308              0.762211        0.722436
6              0.752308              0.762211        0.722436
8              0.752308              0.762211        0.722436
16             0.778462              0.736171        0.770513
18             0.778462              0.736171        0.770513
12             0.778462              0.736171        0.770513
14             0.778462              0.736171        0.770513
10             0.778462              0.736171        0.770513
28             0.736923              0.678097        0.726923
26             0.736923              0.678097        0.726923
20             0.736923              0.678097        0.726923
22             0.736923              0.678097        0.726923
24             0.736923              0.678097        0.726923
42             0.704615              0.634817        0.693590
40             0.704615              0.634817        0.693590
48             0.704615              0.634817        0.693590
44             0.704615              0.634817        0.693590
46             0.704615              0.634817        0.693590
36             0.704615              0.634817        0.693590
50             0.704615              0.634817        0.693590
52             0.704615              0.634817        0.693590
54             0.704615              0.634817        0.693590
56             0.704615              0.634817        0.693590
58             0.704615              0.634817        0.693590
38             0.704615              0.634817        0.693590
30             0.704615              0.634817        0.693590
34             0.704615              0.634817        0.693590
32             0.704615              0.634817        0.693590
35             0.600000              0.000000        0.500000
49             0.600000              0.000000        0.500000
3              0.600000              0.000000        0.500000
57             0.600000              0.000000        0.500000
5              0.600000              0.000000        0.500000
55             0.600000              0.000000        0.500000
7              0.600000              0.000000        0.500000
9              0.600000              0.000000        0.500000
11             0.600000              0.000000        0.500000
13             0.600000              0.000000        0.500000
15             0.600000              0.000000        0.500000
17             0.600000              0.000000        0.500000
37             0.600000              0.000000        0.500000
47             0.600000              0.000000        0.500000
19             0.600000              0.000000        0.500000
45             0.600000              0.000000        0.500000
25             0.600000              0.000000        0.500000
27             0.600000              0.000000        0.500000
29             0.600000              0.000000        0.500000
1              0.600000              0.000000        0.500000
39             0.600000              0.000000        0.500000
59             0.600000              0.000000        0.500000
2023-05-27 00:54:26,519 [INFO] Best model :
SVC(C=1, gamma=0.1, random_state=42)
2023-05-27 00:54:26,561 [INFO] Save train_prediction_log data...
2023-05-27 00:54:26,565 [INFO] {'Data': 'train', 'ACC': '1.0 (650 / 650)', 'TP': 260, 'FP': 0, 'FN': 0, 'TN': 390, 'Precision': '1.0 (260 / 260 + 0)', 'Recall': '1.0 (260 / 260 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (390 / 390 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 00:54:26,578 [INFO] Save valid_prediction_log data...
2023-05-27 00:54:26,580 [INFO] {'Data': 'valid', 'ACC': '0.91 (148 / 163)', 'TP': 51, 'FP': 1, 'FN': 14, 'TN': 97, 'Precision': '0.98 (51 / 51 + 1)', 'Recall': '0.78 (51 / 51 + 14)', 'F1': '0.87 (2 * (0.78 * 0.98) / 0.78 + 0.98)', 'Specificity': '0.99 (97 / 97 + 1)', 'AUC': 0.89, 'r2': 0.62}
2023-05-27 00:54:26,598 [INFO] Save test_prediction_log data...
2023-05-27 00:54:26,600 [INFO] {'Data': 'test', 'ACC': '0.96 (155 / 162)', 'TP': 58, 'FP': 0, 'FN': 7, 'TN': 97, 'Precision': '1.0 (58 / 58 + 0)', 'Recall': '0.89 (58 / 58 + 7)', 'F1': '0.94 (2 * (0.89 * 1.0) / 0.89 + 1.0)', 'Specificity': '1.0 (97 / 97 + 0)', 'AUC': 0.95, 'r2': 0.82}
2023-05-27 00:54:26,602 [INFO] Save training_log data...
2023-05-27 00:54:26,603 [INFO] Save score_log data...
2023-05-27 00:54:26,604 [INFO] Time : 4.088192939758301
