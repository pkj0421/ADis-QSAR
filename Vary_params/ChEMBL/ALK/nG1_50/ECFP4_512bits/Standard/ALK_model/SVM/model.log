2023-05-26 07:22:34,852 [INFO] Train data : Vary_params\ChEMBL\ALK\nG1_50\ECFP4_512bits\Standard\ALK_train_vector.tsv
2023-05-26 07:22:34,852 [INFO] Valid data : Vary_params\ChEMBL\ALK\nG1_50\ECFP4_512bits\Standard\ALK_valid_vector.tsv
2023-05-26 07:22:34,852 [INFO] Output path : Vary_params\ChEMBL\ALK\nG1_50\ECFP4_512bits\Standard\ALK_model\SVM
2023-05-26 07:22:34,853 [INFO] Model type : SVM
2023-05-26 07:22:34,853 [INFO] Use cores : 17
2023-05-26 07:22:34,929 [INFO] Start Learning model
2023-05-26 07:22:34,929 [INFO] Train : 490 | Valid : 123
2023-05-26 07:22:34,929 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-26 07:22:41,278 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.636735              0.966667        0.546960
0              0.951020              0.936337        0.951490
2              0.951020              0.936337        0.951490
4              0.951020              0.936337        0.951490
6              0.951020              0.936337        0.951490
8              0.951020              0.936337        0.951490
31             0.657143              0.930000        0.575060
51             0.657143              0.930000        0.575060
41             0.657143              0.930000        0.575060
42             0.940816              0.920808        0.942266
32             0.940816              0.920808        0.942266
34             0.940816              0.920808        0.942266
36             0.940816              0.920808        0.942266
38             0.940816              0.920808        0.942266
40             0.940816              0.920808        0.942266
48             0.940816              0.920808        0.942266
44             0.940816              0.920808        0.942266
46             0.940816              0.920808        0.942266
26             0.940816              0.920808        0.942266
50             0.940816              0.920808        0.942266
52             0.940816              0.920808        0.942266
54             0.940816              0.920808        0.942266
56             0.940816              0.920808        0.942266
58             0.940816              0.920808        0.942266
28             0.940816              0.920808        0.942266
30             0.940816              0.920808        0.942266
18             0.940816              0.920808        0.942266
24             0.940816              0.920808        0.942266
14             0.940816              0.920808        0.942266
12             0.940816              0.920808        0.942266
22             0.940816              0.920808        0.942266
16             0.940816              0.920808        0.942266
20             0.940816              0.920808        0.942266
10             0.940816              0.920808        0.942266
25             0.600000              0.000000        0.500000
49             0.600000              0.000000        0.500000
11             0.600000              0.000000        0.500000
53             0.600000              0.000000        0.500000
9              0.600000              0.000000        0.500000
13             0.600000              0.000000        0.500000
7              0.600000              0.000000        0.500000
55             0.600000              0.000000        0.500000
5              0.600000              0.000000        0.500000
57             0.600000              0.000000        0.500000
3              0.600000              0.000000        0.500000
47             0.600000              0.000000        0.500000
43             0.600000              0.000000        0.500000
45             0.600000              0.000000        0.500000
27             0.600000              0.000000        0.500000
15             0.600000              0.000000        0.500000
17             0.600000              0.000000        0.500000
39             0.600000              0.000000        0.500000
37             0.600000              0.000000        0.500000
19             0.600000              0.000000        0.500000
35             0.600000              0.000000        0.500000
33             0.600000              0.000000        0.500000
23             0.600000              0.000000        0.500000
1              0.600000              0.000000        0.500000
29             0.600000              0.000000        0.500000
59             0.600000              0.000000        0.500000
2023-05-26 07:22:41,280 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-26 07:22:41,345 [INFO] Save train_prediction_log data...
2023-05-26 07:22:41,349 [INFO] {'Data': 'train', 'ACC': '1.0 (490 / 490)', 'TP': 196, 'FP': 0, 'FN': 0, 'TN': 294, 'Precision': '1.0 (196 / 196 + 0)', 'Recall': '1.0 (196 / 196 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (294 / 294 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-26 07:22:41,369 [INFO] Save valid_prediction_log data...
2023-05-26 07:22:41,372 [INFO] {'Data': 'valid', 'ACC': '0.72 (89 / 123)', 'TP': 15, 'FP': 0, 'FN': 34, 'TN': 74, 'Precision': '1.0 (15 / 15 + 0)', 'Recall': '0.31 (15 / 15 + 34)', 'F1': '0.47 (2 * (0.31 * 1.0) / 0.31 + 1.0)', 'Specificity': '1.0 (74 / 74 + 0)', 'AUC': 0.65, 'r2': -0.15}
2023-05-26 07:22:41,412 [INFO] Save test_prediction_log data...
2023-05-26 07:22:41,415 [INFO] {'Data': 'test', 'ACC': '0.7 (85 / 122)', 'TP': 12, 'FP': 0, 'FN': 37, 'TN': 73, 'Precision': '1.0 (12 / 12 + 0)', 'Recall': '0.24 (12 / 12 + 37)', 'F1': '0.39 (2 * (0.24 * 1.0) / 0.24 + 1.0)', 'Specificity': '1.0 (73 / 73 + 0)', 'AUC': 0.62, 'r2': -0.26}
2023-05-26 07:22:41,418 [INFO] Save training_log data...
2023-05-26 07:22:41,419 [INFO] Save score_log data...
2023-05-26 07:22:41,420 [INFO] Time : 6.567705869674683
