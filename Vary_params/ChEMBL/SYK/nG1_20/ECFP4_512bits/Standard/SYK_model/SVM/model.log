2023-05-27 16:57:22,026 [INFO] Train data : Vary_params\ChEMBL\SYK\nG1_20\ECFP4_512bits\Standard\SYK_train_vector.tsv
2023-05-27 16:57:22,026 [INFO] Valid data : Vary_params\ChEMBL\SYK\nG1_20\ECFP4_512bits\Standard\SYK_valid_vector.tsv
2023-05-27 16:57:22,026 [INFO] Output path : Vary_params\ChEMBL\SYK\nG1_20\ECFP4_512bits\Standard\SYK_model\SVM
2023-05-27 16:57:22,026 [INFO] Model type : SVM
2023-05-27 16:57:22,026 [INFO] Use cores : 18
2023-05-27 16:57:22,087 [INFO] Start Learning model
2023-05-27 16:57:22,087 [INFO] Train : 612 | Valid : 145
2023-05-27 16:57:22,087 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 16:57:28,434 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
21             0.622581              1.000000        0.560969
31             0.645373              0.975000        0.587674
51             0.645373              0.975000        0.587674
41             0.645373              0.975000        0.587674
0              0.908884              0.896836        0.907746
2              0.908884              0.896836        0.907746
4              0.908884              0.896836        0.907746
6              0.908884              0.896836        0.907746
8              0.908884              0.896836        0.907746
42             0.903993              0.886474        0.903812
32             0.903993              0.886474        0.903812
34             0.903993              0.886474        0.903812
36             0.903993              0.886474        0.903812
38             0.903993              0.886474        0.903812
40             0.903993              0.886474        0.903812
48             0.903993              0.886474        0.903812
44             0.903993              0.886474        0.903812
46             0.903993              0.886474        0.903812
26             0.903993              0.886474        0.903812
50             0.903993              0.886474        0.903812
52             0.903993              0.886474        0.903812
54             0.903993              0.886474        0.903812
56             0.903993              0.886474        0.903812
58             0.903993              0.886474        0.903812
28             0.903993              0.886474        0.903812
30             0.903993              0.886474        0.903812
18             0.903993              0.886474        0.903812
24             0.903993              0.886474        0.903812
14             0.903993              0.886474        0.903812
12             0.903993              0.886474        0.903812
22             0.903993              0.886474        0.903812
16             0.903993              0.886474        0.903812
20             0.903993              0.886474        0.903812
10             0.903993              0.886474        0.903812
25             0.570280              0.000000        0.500000
49             0.570280              0.000000        0.500000
11             0.570280              0.000000        0.500000
53             0.570280              0.000000        0.500000
9              0.570280              0.000000        0.500000
13             0.570280              0.000000        0.500000
7              0.570280              0.000000        0.500000
55             0.570280              0.000000        0.500000
5              0.570280              0.000000        0.500000
57             0.570280              0.000000        0.500000
3              0.570280              0.000000        0.500000
47             0.570280              0.000000        0.500000
43             0.570280              0.000000        0.500000
45             0.570280              0.000000        0.500000
27             0.570280              0.000000        0.500000
15             0.570280              0.000000        0.500000
17             0.570280              0.000000        0.500000
39             0.570280              0.000000        0.500000
37             0.570280              0.000000        0.500000
19             0.570280              0.000000        0.500000
35             0.570280              0.000000        0.500000
33             0.570280              0.000000        0.500000
23             0.570280              0.000000        0.500000
1              0.570280              0.000000        0.500000
29             0.570280              0.000000        0.500000
59             0.570280              0.000000        0.500000
2023-05-27 16:57:28,436 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-27 16:57:28,506 [INFO] Save train_prediction_log data...
2023-05-27 16:57:28,510 [INFO] {'Data': 'train', 'ACC': '1.0 (612 / 612)', 'TP': 263, 'FP': 0, 'FN': 0, 'TN': 349, 'Precision': '1.0 (263 / 263 + 0)', 'Recall': '1.0 (263 / 263 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (349 / 349 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 16:57:28,531 [INFO] Save valid_prediction_log data...
2023-05-27 16:57:28,534 [INFO] {'Data': 'valid', 'ACC': '0.68 (99 / 145)', 'TP': 12, 'FP': 0, 'FN': 46, 'TN': 87, 'Precision': '1.0 (12 / 12 + 0)', 'Recall': '0.21 (12 / 12 + 46)', 'F1': '0.35 (2 * (0.21 * 1.0) / 0.21 + 1.0)', 'Specificity': '1.0 (87 / 87 + 0)', 'AUC': 0.6, 'r2': -0.32}
2023-05-27 16:57:28,570 [INFO] Save test_prediction_log data...
2023-05-27 16:57:28,572 [INFO] {'Data': 'test', 'ACC': '0.65 (95 / 146)', 'TP': 7, 'FP': 0, 'FN': 51, 'TN': 88, 'Precision': '1.0 (7 / 7 + 0)', 'Recall': '0.12 (7 / 7 + 51)', 'F1': '0.21 (2 * (0.12 * 1.0) / 0.12 + 1.0)', 'Specificity': '1.0 (88 / 88 + 0)', 'AUC': 0.56, 'r2': -0.46}
2023-05-27 16:57:28,576 [INFO] Save training_log data...
2023-05-27 16:57:28,577 [INFO] Save score_log data...
2023-05-27 16:57:28,578 [INFO] Time : 6.5514349937438965
