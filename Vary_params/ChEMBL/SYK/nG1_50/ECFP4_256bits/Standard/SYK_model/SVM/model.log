2023-05-27 20:38:30,508 [INFO] Train data : Vary_params\ChEMBL\SYK\nG1_50\ECFP4_256bits\Standard\SYK_train_vector.tsv
2023-05-27 20:38:30,508 [INFO] Valid data : Vary_params\ChEMBL\SYK\nG1_50\ECFP4_256bits\Standard\SYK_valid_vector.tsv
2023-05-27 20:38:30,508 [INFO] Output path : Vary_params\ChEMBL\SYK\nG1_50\ECFP4_256bits\Standard\SYK_model\SVM
2023-05-27 20:38:30,508 [INFO] Model type : SVM
2023-05-27 20:38:30,508 [INFO] Use cores : 18
2023-05-27 20:38:30,536 [INFO] Start Learning model
2023-05-27 20:38:30,536 [INFO] Train : 582 | Valid : 145
2023-05-27 20:38:30,536 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 20:38:34,770 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
31             0.910929              0.981818        0.891749
21             0.905757              0.981818        0.885318
51             0.910929              0.981818        0.891749
41             0.910929              0.981818        0.891749
0              0.921303              0.917600        0.916042
2              0.921303              0.917600        0.916042
4              0.921303              0.917600        0.916042
6              0.921303              0.917600        0.916042
8              0.921303              0.917600        0.916042
42             0.909322              0.880641        0.908710
32             0.909322              0.880641        0.908710
34             0.909322              0.880641        0.908710
36             0.909322              0.880641        0.908710
38             0.909322              0.880641        0.908710
40             0.909322              0.880641        0.908710
48             0.909322              0.880641        0.908710
44             0.909322              0.880641        0.908710
46             0.909322              0.880641        0.908710
26             0.909322              0.880641        0.908710
50             0.909322              0.880641        0.908710
52             0.909322              0.880641        0.908710
54             0.909322              0.880641        0.908710
56             0.909322              0.880641        0.908710
58             0.909322              0.880641        0.908710
28             0.909322              0.880641        0.908710
30             0.909322              0.880641        0.908710
18             0.909322              0.880641        0.908710
24             0.909322              0.880641        0.908710
14             0.909322              0.880641        0.908710
12             0.909322              0.880641        0.908710
22             0.909322              0.880641        0.908710
16             0.909322              0.880641        0.908710
20             0.909322              0.880641        0.908710
10             0.909322              0.880641        0.908710
25             0.599679              0.000000        0.500000
49             0.599679              0.000000        0.500000
11             0.599679              0.000000        0.500000
53             0.599679              0.000000        0.500000
9              0.599679              0.000000        0.500000
13             0.599679              0.000000        0.500000
7              0.599679              0.000000        0.500000
55             0.599679              0.000000        0.500000
5              0.599679              0.000000        0.500000
57             0.599679              0.000000        0.500000
3              0.599679              0.000000        0.500000
47             0.599679              0.000000        0.500000
43             0.599679              0.000000        0.500000
45             0.599679              0.000000        0.500000
27             0.599679              0.000000        0.500000
15             0.599679              0.000000        0.500000
17             0.599679              0.000000        0.500000
39             0.599679              0.000000        0.500000
37             0.599679              0.000000        0.500000
19             0.599679              0.000000        0.500000
35             0.599679              0.000000        0.500000
33             0.599679              0.000000        0.500000
23             0.599679              0.000000        0.500000
1              0.599679              0.000000        0.500000
29             0.599679              0.000000        0.500000
59             0.599679              0.000000        0.500000
2023-05-27 20:38:34,772 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-27 20:38:34,805 [INFO] Save train_prediction_log data...
2023-05-27 20:38:34,809 [INFO] {'Data': 'train', 'ACC': '1.0 (582 / 582)', 'TP': 233, 'FP': 0, 'FN': 0, 'TN': 349, 'Precision': '1.0 (233 / 233 + 0)', 'Recall': '1.0 (233 / 233 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (349 / 349 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 20:38:34,819 [INFO] Save valid_prediction_log data...
2023-05-27 20:38:34,821 [INFO] {'Data': 'valid', 'ACC': '0.97 (141 / 145)', 'TP': 54, 'FP': 0, 'FN': 4, 'TN': 87, 'Precision': '1.0 (54 / 54 + 0)', 'Recall': '0.93 (54 / 54 + 4)', 'F1': '0.96 (2 * (0.93 * 1.0) / 0.93 + 1.0)', 'Specificity': '1.0 (87 / 87 + 0)', 'AUC': 0.97, 'r2': 0.89}
2023-05-27 20:38:34,840 [INFO] Save test_prediction_log data...
2023-05-27 20:38:34,842 [INFO] {'Data': 'test', 'ACC': '1.0 (146 / 146)', 'TP': 58, 'FP': 0, 'FN': 0, 'TN': 88, 'Precision': '1.0 (58 / 58 + 0)', 'Recall': '1.0 (58 / 58 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (88 / 88 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 20:38:34,845 [INFO] Save training_log data...
2023-05-27 20:38:34,845 [INFO] Save score_log data...
2023-05-27 20:38:34,846 [INFO] Time : 4.338880777359009
