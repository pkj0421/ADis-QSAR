2023-05-28 00:53:03,551 [INFO] Train data : Vary_params\ChEMBL\SYK\nG1_50\ECFP6_512bits\MinMax\SYK_train_vector.tsv
2023-05-28 00:53:03,551 [INFO] Valid data : Vary_params\ChEMBL\SYK\nG1_50\ECFP6_512bits\MinMax\SYK_valid_vector.tsv
2023-05-28 00:53:03,551 [INFO] Output path : Vary_params\ChEMBL\SYK\nG1_50\ECFP6_512bits\MinMax\SYK_model\SVM
2023-05-28 00:53:03,551 [INFO] Model type : SVM
2023-05-28 00:53:03,551 [INFO] Use cores : 18
2023-05-28 00:53:03,581 [INFO] Start Learning model
2023-05-28 00:53:03,581 [INFO] Train : 582 | Valid : 145
2023-05-28 00:53:03,581 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 00:53:09,327 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
41             0.953799              0.948916        0.952101
31             0.953799              0.948916        0.952101
51             0.953799              0.948916        0.952101
21             0.941788              0.947573        0.936592
0              0.926330              0.928912        0.920753
2              0.926330              0.928912        0.920753
4              0.926330              0.928912        0.920753
6              0.926330              0.928912        0.920753
8              0.926330              0.928912        0.920753
12             0.938252              0.924112        0.937008
18             0.938252              0.924112        0.937008
16             0.938252              0.924112        0.937008
14             0.938252              0.924112        0.937008
10             0.938252              0.924112        0.937008
50             0.938282              0.922636        0.937008
48             0.938282              0.922636        0.937008
52             0.938282              0.922636        0.937008
46             0.938282              0.922636        0.937008
54             0.938282              0.922636        0.937008
44             0.938282              0.922636        0.937008
42             0.938282              0.922636        0.937008
56             0.938282              0.922636        0.937008
58             0.938282              0.922636        0.937008
40             0.938282              0.922636        0.937008
38             0.938282              0.922636        0.937008
36             0.938282              0.922636        0.937008
34             0.938282              0.922636        0.937008
32             0.938282              0.922636        0.937008
30             0.938282              0.922636        0.937008
24             0.938282              0.922636        0.937008
28             0.938282              0.922636        0.937008
26             0.938282              0.922636        0.937008
20             0.938282              0.922636        0.937008
22             0.938282              0.922636        0.937008
33             0.608212              0.300000        0.510598
53             0.608212              0.300000        0.510598
43             0.608212              0.300000        0.510598
23             0.601403              0.100000        0.502174
11             0.599679              0.000000        0.500000
9              0.599679              0.000000        0.500000
29             0.599679              0.000000        0.500000
7              0.599679              0.000000        0.500000
49             0.599679              0.000000        0.500000
55             0.599679              0.000000        0.500000
5              0.599679              0.000000        0.500000
57             0.599679              0.000000        0.500000
3              0.599679              0.000000        0.500000
13             0.599679              0.000000        0.500000
19             0.599679              0.000000        0.500000
15             0.599679              0.000000        0.500000
47             0.599679              0.000000        0.500000
17             0.599679              0.000000        0.500000
45             0.599679              0.000000        0.500000
1              0.599679              0.000000        0.500000
39             0.599679              0.000000        0.500000
37             0.599679              0.000000        0.500000
25             0.599679              0.000000        0.500000
35             0.599679              0.000000        0.500000
27             0.599679              0.000000        0.500000
59             0.599679              0.000000        0.500000
2023-05-28 00:53:09,327 [INFO] Best model :
SVC(C=10, gamma=0.01, random_state=42)
2023-05-28 00:53:09,367 [INFO] Save train_prediction_log data...
2023-05-28 00:53:09,377 [INFO] {'Data': 'train', 'ACC': '1.0 (582 / 582)', 'TP': 233, 'FP': 0, 'FN': 0, 'TN': 349, 'Precision': '1.0 (233 / 233 + 0)', 'Recall': '1.0 (233 / 233 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (349 / 349 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 00:53:09,387 [INFO] Save valid_prediction_log data...
2023-05-28 00:53:09,387 [INFO] {'Data': 'valid', 'ACC': '0.99 (143 / 145)', 'TP': 56, 'FP': 0, 'FN': 2, 'TN': 87, 'Precision': '1.0 (56 / 56 + 0)', 'Recall': '0.97 (56 / 56 + 2)', 'F1': '0.98 (2 * (0.97 * 1.0) / 0.97 + 1.0)', 'Specificity': '1.0 (87 / 87 + 0)', 'AUC': 0.98, 'r2': 0.94}
2023-05-28 00:53:09,407 [INFO] Save test_prediction_log data...
2023-05-28 00:53:09,407 [INFO] {'Data': 'test', 'ACC': '1.0 (146 / 146)', 'TP': 58, 'FP': 0, 'FN': 0, 'TN': 88, 'Precision': '1.0 (58 / 58 + 0)', 'Recall': '1.0 (58 / 58 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (88 / 88 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 00:53:09,417 [INFO] Save training_log data...
2023-05-28 00:53:09,417 [INFO] Save score_log data...
2023-05-28 00:53:09,417 [INFO] Time : 5.86588191986084
