2023-05-28 01:12:31,046 [INFO] Train data : Vary_params\ChEMBL\SYK\nG1_80\ECFP4_256bits\Robust\SYK_train_vector.tsv
2023-05-28 01:12:31,046 [INFO] Valid data : Vary_params\ChEMBL\SYK\nG1_80\ECFP4_256bits\Robust\SYK_valid_vector.tsv
2023-05-28 01:12:31,046 [INFO] Output path : Vary_params\ChEMBL\SYK\nG1_80\ECFP4_256bits\Robust\SYK_model\SVM
2023-05-28 01:12:31,046 [INFO] Model type : SVM
2023-05-28 01:12:31,046 [INFO] Use cores : 18
2023-05-28 01:12:31,063 [INFO] Start Learning model
2023-05-28 01:12:31,063 [INFO] Train : 552 | Valid : 145
2023-05-28 01:12:31,063 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 01:12:35,252 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.869708              0.831142         0.86222
20             0.869708              0.831142         0.86222
24             0.869708              0.831142         0.86222
26             0.869708              0.831142         0.86222
28             0.869708              0.831142         0.86222
32             0.869708              0.831142         0.86222
34             0.869708              0.831142         0.86222
36             0.869708              0.831142         0.86222
38             0.869708              0.831142         0.86222
40             0.869708              0.831142         0.86222
42             0.869708              0.831142         0.86222
44             0.869708              0.831142         0.86222
46             0.869708              0.831142         0.86222
48             0.869708              0.831142         0.86222
50             0.869708              0.831142         0.86222
52             0.869708              0.831142         0.86222
54             0.869708              0.831142         0.86222
56             0.869708              0.831142         0.86222
58             0.869708              0.831142         0.86222
22             0.869708              0.831142         0.86222
30             0.869708              0.831142         0.86222
10             0.869708              0.831142         0.86222
2              0.869708              0.831142         0.86222
18             0.869708              0.831142         0.86222
8              0.869708              0.831142         0.86222
16             0.869708              0.831142         0.86222
4              0.869708              0.831142         0.86222
12             0.869708              0.831142         0.86222
6              0.869708              0.831142         0.86222
14             0.869708              0.831142         0.86222
49             0.632273              0.000000         0.50000
9              0.632273              0.000000         0.50000
45             0.632273              0.000000         0.50000
47             0.632273              0.000000         0.50000
7              0.632273              0.000000         0.50000
21             0.632273              0.000000         0.50000
43             0.632273              0.000000         0.50000
5              0.632273              0.000000         0.50000
53             0.632273              0.000000         0.50000
55             0.632273              0.000000         0.50000
3              0.632273              0.000000         0.50000
57             0.632273              0.000000         0.50000
51             0.632273              0.000000         0.50000
11             0.632273              0.000000         0.50000
41             0.632273              0.000000         0.50000
19             0.632273              0.000000         0.50000
39             0.632273              0.000000         0.50000
37             0.632273              0.000000         0.50000
13             0.632273              0.000000         0.50000
35             0.632273              0.000000         0.50000
33             0.632273              0.000000         0.50000
15             0.632273              0.000000         0.50000
31             0.632273              0.000000         0.50000
1              0.632273              0.000000         0.50000
29             0.632273              0.000000         0.50000
27             0.632273              0.000000         0.50000
17             0.632273              0.000000         0.50000
25             0.632273              0.000000         0.50000
23             0.632273              0.000000         0.50000
59             0.632273              0.000000         0.50000
2023-05-28 01:12:35,254 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-28 01:12:35,261 [INFO] Save train_prediction_log data...
2023-05-28 01:12:35,265 [INFO] {'Data': 'train', 'ACC': '1.0 (552 / 552)', 'TP': 203, 'FP': 0, 'FN': 0, 'TN': 349, 'Precision': '1.0 (203 / 203 + 0)', 'Recall': '1.0 (203 / 203 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (349 / 349 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 01:12:35,269 [INFO] Save valid_prediction_log data...
2023-05-28 01:12:35,271 [INFO] {'Data': 'valid', 'ACC': '0.92 (134 / 145)', 'TP': 52, 'FP': 5, 'FN': 6, 'TN': 82, 'Precision': '0.91 (52 / 52 + 5)', 'Recall': '0.9 (52 / 52 + 6)', 'F1': '0.9 (2 * (0.9 * 0.91) / 0.9 + 0.91)', 'Specificity': '0.94 (82 / 82 + 5)', 'AUC': 0.92, 'r2': 0.68}
2023-05-28 01:12:35,280 [INFO] Save test_prediction_log data...
2023-05-28 01:12:35,282 [INFO] {'Data': 'test', 'ACC': '0.95 (139 / 146)', 'TP': 54, 'FP': 3, 'FN': 4, 'TN': 85, 'Precision': '0.95 (54 / 54 + 3)', 'Recall': '0.93 (54 / 54 + 4)', 'F1': '0.94 (2 * (0.93 * 0.95) / 0.93 + 0.95)', 'Specificity': '0.97 (85 / 85 + 3)', 'AUC': 0.95, 'r2': 0.8}
2023-05-28 01:12:35,283 [INFO] Save training_log data...
2023-05-28 01:12:35,285 [INFO] Save score_log data...
2023-05-28 01:12:35,286 [INFO] Time : 4.239626884460449
