2023-05-28 03:09:39,179 [INFO] Train data : Vary_params\ChEMBL\SYK\nG1_80\ECFP4_512bits\MinMax\SYK_train_vector.tsv
2023-05-28 03:09:39,179 [INFO] Valid data : Vary_params\ChEMBL\SYK\nG1_80\ECFP4_512bits\MinMax\SYK_valid_vector.tsv
2023-05-28 03:09:39,179 [INFO] Output path : Vary_params\ChEMBL\SYK\nG1_80\ECFP4_512bits\MinMax\SYK_model\SVM
2023-05-28 03:09:39,179 [INFO] Model type : SVM
2023-05-28 03:09:39,179 [INFO] Use cores : 18
2023-05-28 03:09:39,209 [INFO] Start Learning model
2023-05-28 03:09:39,209 [INFO] Train : 552 | Valid : 145
2023-05-28 03:09:39,209 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 03:09:44,498 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
23             0.748279              0.987500        0.658810
53             0.789903              0.982576        0.716429
33             0.789903              0.982576        0.716429
43             0.789903              0.982576        0.716429
21             0.936753              0.941140        0.927339
31             0.949578              0.939675        0.946905
41             0.949578              0.939675        0.946905
51             0.949578              0.939675        0.946905
0              0.925909              0.928804        0.914720
8              0.925909              0.928804        0.914720
2              0.925909              0.928804        0.914720
4              0.925909              0.928804        0.914720
6              0.925909              0.928804        0.914720
18             0.940519              0.922357        0.939720
10             0.940519              0.922357        0.939720
16             0.940519              0.922357        0.939720
14             0.940519              0.922357        0.939720
12             0.940519              0.922357        0.939720
32             0.936916              0.912765        0.936982
48             0.936916              0.912765        0.936982
50             0.936916              0.912765        0.936982
46             0.936916              0.912765        0.936982
54             0.936916              0.912765        0.936982
56             0.936916              0.912765        0.936982
42             0.936916              0.912765        0.936982
58             0.936916              0.912765        0.936982
40             0.936916              0.912765        0.936982
38             0.936916              0.912765        0.936982
36             0.936916              0.912765        0.936982
34             0.936916              0.912765        0.936982
52             0.936916              0.912765        0.936982
44             0.936916              0.912765        0.936982
30             0.936916              0.912765        0.936982
28             0.936916              0.912765        0.936982
26             0.936916              0.912765        0.936982
24             0.936916              0.912765        0.936982
22             0.936916              0.912765        0.936982
20             0.936916              0.912765        0.936982
1              0.632273              0.000000        0.500000
49             0.632273              0.000000        0.500000
3              0.632273              0.000000        0.500000
57             0.632273              0.000000        0.500000
5              0.632273              0.000000        0.500000
55             0.632273              0.000000        0.500000
7              0.632273              0.000000        0.500000
9              0.632273              0.000000        0.500000
11             0.632273              0.000000        0.500000
13             0.632273              0.000000        0.500000
15             0.632273              0.000000        0.500000
19             0.632273              0.000000        0.500000
17             0.632273              0.000000        0.500000
47             0.632273              0.000000        0.500000
29             0.632273              0.000000        0.500000
45             0.632273              0.000000        0.500000
25             0.632273              0.000000        0.500000
39             0.632273              0.000000        0.500000
27             0.632273              0.000000        0.500000
37             0.632273              0.000000        0.500000
35             0.632273              0.000000        0.500000
59             0.632273              0.000000        0.500000
2023-05-28 03:09:44,500 [INFO] Best model :
SVC(C=1, gamma=0.1, random_state=42)
2023-05-28 03:09:44,550 [INFO] Save train_prediction_log data...
2023-05-28 03:09:44,554 [INFO] {'Data': 'train', 'ACC': '1.0 (552 / 552)', 'TP': 203, 'FP': 0, 'FN': 0, 'TN': 349, 'Precision': '1.0 (203 / 203 + 0)', 'Recall': '1.0 (203 / 203 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (349 / 349 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 03:09:44,571 [INFO] Save valid_prediction_log data...
2023-05-28 03:09:44,573 [INFO] {'Data': 'valid', 'ACC': '0.77 (112 / 145)', 'TP': 25, 'FP': 0, 'FN': 33, 'TN': 87, 'Precision': '1.0 (25 / 25 + 0)', 'Recall': '0.43 (25 / 25 + 33)', 'F1': '0.6 (2 * (0.43 * 1.0) / 0.43 + 1.0)', 'Specificity': '1.0 (87 / 87 + 0)', 'AUC': 0.72, 'r2': 0.05}
2023-05-28 03:09:44,600 [INFO] Save test_prediction_log data...
2023-05-28 03:09:44,602 [INFO] {'Data': 'test', 'ACC': '0.79 (116 / 146)', 'TP': 28, 'FP': 0, 'FN': 30, 'TN': 88, 'Precision': '1.0 (28 / 28 + 0)', 'Recall': '0.48 (28 / 28 + 30)', 'F1': '0.65 (2 * (0.48 * 1.0) / 0.48 + 1.0)', 'Specificity': '1.0 (88 / 88 + 0)', 'AUC': 0.74, 'r2': 0.14}
2023-05-28 03:09:44,604 [INFO] Save training_log data...
2023-05-28 03:09:44,605 [INFO] Save score_log data...
2023-05-28 03:09:44,606 [INFO] Time : 5.427391529083252
