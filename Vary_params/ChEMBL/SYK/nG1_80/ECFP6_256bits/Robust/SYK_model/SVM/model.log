2023-05-28 03:29:15,486 [INFO] Train data : Vary_params\ChEMBL\SYK\nG1_80\ECFP6_256bits\Robust\SYK_train_vector.tsv
2023-05-28 03:29:15,486 [INFO] Valid data : Vary_params\ChEMBL\SYK\nG1_80\ECFP6_256bits\Robust\SYK_valid_vector.tsv
2023-05-28 03:29:15,486 [INFO] Output path : Vary_params\ChEMBL\SYK\nG1_80\ECFP6_256bits\Robust\SYK_model\SVM
2023-05-28 03:29:15,486 [INFO] Model type : SVM
2023-05-28 03:29:15,486 [INFO] Use cores : 18
2023-05-28 03:29:15,504 [INFO] Start Learning model
2023-05-28 03:29:15,504 [INFO] Train : 552 | Valid : 145
2023-05-28 03:29:15,504 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 03:29:19,780 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.829773              0.772521        0.822136
20             0.829773              0.772521        0.822136
24             0.829773              0.772521        0.822136
26             0.829773              0.772521        0.822136
28             0.829773              0.772521        0.822136
32             0.829773              0.772521        0.822136
34             0.829773              0.772521        0.822136
36             0.829773              0.772521        0.822136
38             0.829773              0.772521        0.822136
40             0.829773              0.772521        0.822136
42             0.829773              0.772521        0.822136
44             0.829773              0.772521        0.822136
46             0.829773              0.772521        0.822136
48             0.829773              0.772521        0.822136
50             0.829773              0.772521        0.822136
52             0.829773              0.772521        0.822136
54             0.829773              0.772521        0.822136
56             0.829773              0.772521        0.822136
58             0.829773              0.772521        0.822136
22             0.829773              0.772521        0.822136
30             0.829773              0.772521        0.822136
10             0.829773              0.772521        0.822136
2              0.829773              0.772521        0.822136
18             0.829773              0.772521        0.822136
8              0.829773              0.772521        0.822136
16             0.829773              0.772521        0.822136
4              0.829773              0.772521        0.822136
12             0.829773              0.772521        0.822136
6              0.829773              0.772521        0.822136
14             0.829773              0.772521        0.822136
49             0.632273              0.000000        0.500000
9              0.632273              0.000000        0.500000
45             0.632273              0.000000        0.500000
47             0.632273              0.000000        0.500000
7              0.632273              0.000000        0.500000
21             0.632273              0.000000        0.500000
43             0.632273              0.000000        0.500000
5              0.632273              0.000000        0.500000
53             0.632273              0.000000        0.500000
55             0.632273              0.000000        0.500000
3              0.632273              0.000000        0.500000
57             0.632273              0.000000        0.500000
51             0.632273              0.000000        0.500000
11             0.632273              0.000000        0.500000
41             0.632273              0.000000        0.500000
19             0.632273              0.000000        0.500000
39             0.632273              0.000000        0.500000
37             0.632273              0.000000        0.500000
13             0.632273              0.000000        0.500000
35             0.632273              0.000000        0.500000
33             0.632273              0.000000        0.500000
15             0.632273              0.000000        0.500000
31             0.632273              0.000000        0.500000
1              0.632273              0.000000        0.500000
29             0.632273              0.000000        0.500000
27             0.632273              0.000000        0.500000
17             0.632273              0.000000        0.500000
25             0.632273              0.000000        0.500000
23             0.632273              0.000000        0.500000
59             0.632273              0.000000        0.500000
2023-05-28 03:29:19,780 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-28 03:29:19,790 [INFO] Save train_prediction_log data...
2023-05-28 03:29:19,790 [INFO] {'Data': 'train', 'ACC': '1.0 (552 / 552)', 'TP': 203, 'FP': 0, 'FN': 0, 'TN': 349, 'Precision': '1.0 (203 / 203 + 0)', 'Recall': '1.0 (203 / 203 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (349 / 349 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 03:29:19,800 [INFO] Save valid_prediction_log data...
2023-05-28 03:29:19,800 [INFO] {'Data': 'valid', 'ACC': '0.85 (123 / 145)', 'TP': 50, 'FP': 14, 'FN': 8, 'TN': 73, 'Precision': '0.78 (50 / 50 + 14)', 'Recall': '0.86 (50 / 50 + 8)', 'F1': '0.82 (2 * (0.86 * 0.78) / 0.86 + 0.78)', 'Specificity': '0.84 (73 / 73 + 14)', 'AUC': 0.85, 'r2': 0.37}
2023-05-28 03:29:19,810 [INFO] Save test_prediction_log data...
2023-05-28 03:29:19,810 [INFO] {'Data': 'test', 'ACC': '0.89 (130 / 146)', 'TP': 51, 'FP': 9, 'FN': 7, 'TN': 79, 'Precision': '0.85 (51 / 51 + 9)', 'Recall': '0.88 (51 / 51 + 7)', 'F1': '0.86 (2 * (0.88 * 0.85) / 0.88 + 0.85)', 'Specificity': '0.9 (79 / 79 + 9)', 'AUC': 0.89, 'r2': 0.54}
2023-05-28 03:29:19,810 [INFO] Save training_log data...
2023-05-28 03:29:19,810 [INFO] Save score_log data...
2023-05-28 03:29:19,817 [INFO] Time : 4.331420183181763
