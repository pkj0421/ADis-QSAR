2023-05-28 17:57:24,704 [INFO] Train data : Vary_params_FGFR1\DUD-E\FGFR1\nG1_20\ECFP6_256bits\MinMax\FGFR1_train_vector.tsv
2023-05-28 17:57:24,705 [INFO] Valid data : Vary_params_FGFR1\DUD-E\FGFR1\nG1_20\ECFP6_256bits\MinMax\FGFR1_valid_vector.tsv
2023-05-28 17:57:24,705 [INFO] Output path : Vary_params_FGFR1\DUD-E\FGFR1\nG1_20\ECFP6_256bits\MinMax\FGFR1_model\SVM
2023-05-28 17:57:24,705 [INFO] Model type : SVM
2023-05-28 17:57:24,705 [INFO] Use cores : 10
2023-05-28 17:57:24,720 [INFO] Start Learning model
2023-05-28 17:57:24,720 [INFO] Train : 203 | Valid : 43
2023-05-28 17:57:24,721 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 17:57:31,032 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
43             0.825238              1.000000        0.819444
33             0.825238              1.000000        0.819444
23             0.800476              1.000000        0.793889
53             0.825238              1.000000        0.819444
21             0.918095              0.980909        0.915455
0              0.927381              0.971818        0.925455
2              0.927381              0.971818        0.925455
4              0.927381              0.971818        0.925455
6              0.927381              0.971818        0.925455
8              0.927381              0.971818        0.925455
41             0.912381              0.922684        0.911364
31             0.912381              0.922684        0.911364
51             0.912381              0.922684        0.911364
50             0.882619              0.882532        0.882273
48             0.882619              0.882532        0.882273
28             0.882619              0.882532        0.882273
44             0.882619              0.882532        0.882273
42             0.882619              0.882532        0.882273
52             0.882619              0.882532        0.882273
40             0.882619              0.882532        0.882273
38             0.882619              0.882532        0.882273
54             0.882619              0.882532        0.882273
36             0.882619              0.882532        0.882273
56             0.882619              0.882532        0.882273
34             0.882619              0.882532        0.882273
58             0.882619              0.882532        0.882273
32             0.882619              0.882532        0.882273
46             0.882619              0.882532        0.882273
30             0.882619              0.882532        0.882273
20             0.882619              0.882532        0.882273
14             0.882619              0.882532        0.882273
26             0.882619              0.882532        0.882273
12             0.882619              0.882532        0.882273
24             0.882619              0.882532        0.882273
22             0.882619              0.882532        0.882273
16             0.882619              0.882532        0.882273
10             0.882619              0.882532        0.882273
18             0.882619              0.882532        0.882273
11             0.521905              0.200000        0.510000
9              0.512143              0.000000        0.500000
29             0.512143              0.000000        0.500000
7              0.512143              0.000000        0.500000
13             0.512143              0.000000        0.500000
55             0.512143              0.000000        0.500000
5              0.512143              0.000000        0.500000
57             0.512143              0.000000        0.500000
3              0.512143              0.000000        0.500000
49             0.512143              0.000000        0.500000
15             0.512143              0.000000        0.500000
47             0.512143              0.000000        0.500000
45             0.512143              0.000000        0.500000
1              0.512143              0.000000        0.500000
17             0.512143              0.000000        0.500000
19             0.512143              0.000000        0.500000
39             0.512143              0.000000        0.500000
37             0.512143              0.000000        0.500000
35             0.512143              0.000000        0.500000
25             0.512143              0.000000        0.500000
27             0.512143              0.000000        0.500000
59             0.512143              0.000000        0.500000
2023-05-28 17:57:31,034 [INFO] Best model :
SVC(C=1, gamma=0.1, random_state=42)
2023-05-28 17:57:31,046 [INFO] Save train_prediction_log data...
2023-05-28 17:57:31,050 [INFO] {'Data': 'train', 'ACC': '1.0 (203 / 203)', 'TP': 99, 'FP': 0, 'FN': 0, 'TN': 104, 'Precision': '1.0 (99 / 99 + 0)', 'Recall': '1.0 (99 / 99 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (104 / 104 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 17:57:31,057 [INFO] Save valid_prediction_log data...
2023-05-28 17:57:31,060 [INFO] {'Data': 'valid', 'ACC': '1.0 (43 / 43)', 'TP': 17, 'FP': 0, 'FN': 0, 'TN': 26, 'Precision': '1.0 (17 / 17 + 0)', 'Recall': '1.0 (17 / 17 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (26 / 26 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 17:57:31,075 [INFO] Save test_prediction_log data...
2023-05-28 17:57:31,078 [INFO] {'Data': 'test', 'ACC': '0.63 (27 / 43)', 'TP': 1, 'FP': 0, 'FN': 16, 'TN': 26, 'Precision': '1.0 (1 / 1 + 0)', 'Recall': '0.06 (1 / 1 + 16)', 'F1': '0.11 (2 * (0.06 * 1.0) / 0.06 + 1.0)', 'Specificity': '1.0 (26 / 26 + 0)', 'AUC': 0.53, 'r2': -0.56}
2023-05-28 17:57:31,081 [INFO] Save training_log data...
2023-05-28 17:57:31,083 [INFO] Save score_log data...
2023-05-28 17:57:31,085 [INFO] Time : 6.380020618438721
