2023-05-28 01:31:55,186 [INFO] Train data : Vary_params\DUD-E\PLK1\nG1_80\ECFP6_512bits\MinMax\PLK1_train_vector.tsv
2023-05-28 01:31:55,186 [INFO] Valid data : Vary_params\DUD-E\PLK1\nG1_80\ECFP6_512bits\MinMax\PLK1_valid_vector.tsv
2023-05-28 01:31:55,186 [INFO] Output path : Vary_params\DUD-E\PLK1\nG1_80\ECFP6_512bits\MinMax\PLK1_model\SVM
2023-05-28 01:31:55,186 [INFO] Model type : SVM
2023-05-28 01:31:55,186 [INFO] Use cores : 10
2023-05-28 01:31:55,219 [INFO] Start Learning model
2023-05-28 01:31:55,219 [INFO] Train : 84 | Valid : 28
2023-05-28 01:31:55,219 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 01:32:02,046 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.943056                   0.8           0.850
22             0.943056                   0.8           0.850
26             0.943056                   0.8           0.850
28             0.943056                   0.8           0.850
31             0.943056                   0.8           0.850
32             0.943056                   0.8           0.850
34             0.943056                   0.8           0.850
36             0.943056                   0.8           0.850
38             0.943056                   0.8           0.850
40             0.943056                   0.8           0.850
41             0.943056                   0.8           0.850
42             0.943056                   0.8           0.850
44             0.943056                   0.8           0.850
46             0.943056                   0.8           0.850
48             0.943056                   0.8           0.850
50             0.943056                   0.8           0.850
51             0.943056                   0.8           0.850
52             0.943056                   0.8           0.850
54             0.943056                   0.8           0.850
56             0.943056                   0.8           0.850
58             0.943056                   0.8           0.850
24             0.943056                   0.8           0.850
30             0.943056                   0.8           0.850
12             0.943056                   0.8           0.850
4              0.943056                   0.8           0.850
8              0.943056                   0.8           0.850
14             0.943056                   0.8           0.850
6              0.943056                   0.8           0.850
18             0.943056                   0.8           0.850
16             0.943056                   0.8           0.850
20             0.943056                   0.8           0.850
2              0.943056                   0.8           0.850
10             0.943056                   0.8           0.850
21             0.931944                   0.7           0.825
53             0.834722                   0.2           0.550
33             0.834722                   0.2           0.550
43             0.834722                   0.2           0.550
55             0.811111                   0.0           0.500
3              0.811111                   0.0           0.500
9              0.811111                   0.0           0.500
5              0.811111                   0.0           0.500
57             0.811111                   0.0           0.500
7              0.811111                   0.0           0.500
49             0.811111                   0.0           0.500
47             0.811111                   0.0           0.500
23             0.811111                   0.0           0.500
45             0.811111                   0.0           0.500
11             0.811111                   0.0           0.500
13             0.811111                   0.0           0.500
39             0.811111                   0.0           0.500
37             0.811111                   0.0           0.500
15             0.811111                   0.0           0.500
35             0.811111                   0.0           0.500
17             0.811111                   0.0           0.500
1              0.811111                   0.0           0.500
29             0.811111                   0.0           0.500
19             0.811111                   0.0           0.500
27             0.811111                   0.0           0.500
25             0.811111                   0.0           0.500
59             0.811111                   0.0           0.500
2023-05-28 01:32:02,047 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-28 01:32:02,056 [INFO] Save train_prediction_log data...
2023-05-28 01:32:02,061 [INFO] {'Data': 'train', 'ACC': '0.95 (80 / 84)', 'TP': 12, 'FP': 0, 'FN': 4, 'TN': 68, 'Precision': '1.0 (12 / 12 + 0)', 'Recall': '0.75 (12 / 12 + 4)', 'F1': '0.86 (2 * (0.75 * 1.0) / 0.75 + 1.0)', 'Specificity': '1.0 (68 / 68 + 0)', 'AUC': 0.88, 'r2': 0.69}
2023-05-28 01:32:02,068 [INFO] Save valid_prediction_log data...
2023-05-28 01:32:02,071 [INFO] {'Data': 'valid', 'ACC': '1.0 (28 / 28)', 'TP': 11, 'FP': 0, 'FN': 0, 'TN': 17, 'Precision': '1.0 (11 / 11 + 0)', 'Recall': '1.0 (11 / 11 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (17 / 17 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 01:32:02,089 [INFO] Save test_prediction_log data...
2023-05-28 01:32:02,092 [INFO] {'Data': 'test', 'ACC': '0.61 (17 / 28)', 'TP': 1, 'FP': 1, 'FN': 10, 'TN': 16, 'Precision': '0.5 (1 / 1 + 1)', 'Recall': '0.09 (1 / 1 + 10)', 'F1': '0.15 (2 * (0.09 * 0.5) / 0.09 + 0.5)', 'Specificity': '0.94 (16 / 16 + 1)', 'AUC': 0.52, 'r2': -0.65}
2023-05-28 01:32:02,096 [INFO] Save training_log data...
2023-05-28 01:32:02,098 [INFO] Save score_log data...
2023-05-28 01:32:02,100 [INFO] Time : 6.914026737213135
