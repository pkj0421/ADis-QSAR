2023-05-28 11:05:32,819 [INFO] Train data : Vary_params_IGF1R_KIT\DUD-E\IGF1R\nG1_80\ECFP6_256bits\Robust\IGF1R_train_vector.tsv
2023-05-28 11:05:32,819 [INFO] Valid data : Vary_params_IGF1R_KIT\DUD-E\IGF1R\nG1_80\ECFP6_256bits\Robust\IGF1R_valid_vector.tsv
2023-05-28 11:05:32,819 [INFO] Output path : Vary_params_IGF1R_KIT\DUD-E\IGF1R\nG1_80\ECFP6_256bits\Robust\IGF1R_model\SVM
2023-05-28 11:05:32,819 [INFO] Model type : SVM
2023-05-28 11:05:32,819 [INFO] Use cores : 10
2023-05-28 11:05:32,831 [INFO] Start Learning model
2023-05-28 11:05:32,831 [INFO] Train : 166 | Valid : 49
2023-05-28 11:05:32,832 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 11:05:35,175 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.903309              0.856667         0.88553
20             0.903309              0.856667         0.88553
24             0.903309              0.856667         0.88553
26             0.903309              0.856667         0.88553
28             0.903309              0.856667         0.88553
32             0.903309              0.856667         0.88553
34             0.903309              0.856667         0.88553
36             0.903309              0.856667         0.88553
38             0.903309              0.856667         0.88553
40             0.903309              0.856667         0.88553
42             0.903309              0.856667         0.88553
44             0.903309              0.856667         0.88553
46             0.903309              0.856667         0.88553
48             0.903309              0.856667         0.88553
50             0.903309              0.856667         0.88553
52             0.903309              0.856667         0.88553
54             0.903309              0.856667         0.88553
56             0.903309              0.856667         0.88553
58             0.903309              0.856667         0.88553
22             0.903309              0.856667         0.88553
30             0.903309              0.856667         0.88553
10             0.903309              0.856667         0.88553
2              0.903309              0.856667         0.88553
18             0.903309              0.856667         0.88553
8              0.903309              0.856667         0.88553
16             0.903309              0.856667         0.88553
4              0.903309              0.856667         0.88553
12             0.903309              0.856667         0.88553
6              0.903309              0.856667         0.88553
14             0.903309              0.856667         0.88553
49             0.711029              0.000000         0.50000
9              0.711029              0.000000         0.50000
45             0.711029              0.000000         0.50000
47             0.711029              0.000000         0.50000
7              0.711029              0.000000         0.50000
21             0.711029              0.000000         0.50000
43             0.711029              0.000000         0.50000
5              0.711029              0.000000         0.50000
53             0.711029              0.000000         0.50000
55             0.711029              0.000000         0.50000
3              0.711029              0.000000         0.50000
57             0.711029              0.000000         0.50000
51             0.711029              0.000000         0.50000
11             0.711029              0.000000         0.50000
41             0.711029              0.000000         0.50000
19             0.711029              0.000000         0.50000
39             0.711029              0.000000         0.50000
37             0.711029              0.000000         0.50000
13             0.711029              0.000000         0.50000
35             0.711029              0.000000         0.50000
33             0.711029              0.000000         0.50000
15             0.711029              0.000000         0.50000
31             0.711029              0.000000         0.50000
1              0.711029              0.000000         0.50000
29             0.711029              0.000000         0.50000
27             0.711029              0.000000         0.50000
17             0.711029              0.000000         0.50000
25             0.711029              0.000000         0.50000
23             0.711029              0.000000         0.50000
59             0.711029              0.000000         0.50000
2023-05-28 11:05:35,176 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-28 11:05:35,181 [INFO] Save train_prediction_log data...
2023-05-28 11:05:35,184 [INFO] {'Data': 'train', 'ACC': '1.0 (166 / 166)', 'TP': 48, 'FP': 0, 'FN': 0, 'TN': 118, 'Precision': '1.0 (48 / 48 + 0)', 'Recall': '1.0 (48 / 48 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (118 / 118 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 11:05:35,188 [INFO] Save valid_prediction_log data...
2023-05-28 11:05:35,190 [INFO] {'Data': 'valid', 'ACC': '0.92 (45 / 49)', 'TP': 20, 'FP': 4, 'FN': 0, 'TN': 25, 'Precision': '0.83 (20 / 20 + 4)', 'Recall': '1.0 (20 / 20 + 0)', 'F1': '0.91 (2 * (1.0 * 0.83) / 1.0 + 0.83)', 'Specificity': '0.86 (25 / 25 + 4)', 'AUC': 0.93, 'r2': 0.66}
2023-05-28 11:05:35,199 [INFO] Save test_prediction_log data...
2023-05-28 11:05:35,201 [INFO] {'Data': 'test', 'ACC': '0.57 (28 / 49)', 'TP': 8, 'FP': 9, 'FN': 12, 'TN': 20, 'Precision': '0.47 (8 / 8 + 9)', 'Recall': '0.4 (8 / 8 + 12)', 'F1': '0.43 (2 * (0.4 * 0.47) / 0.4 + 0.47)', 'Specificity': '0.69 (20 / 20 + 9)', 'AUC': 0.54, 'r2': -0.77}
2023-05-28 11:05:35,203 [INFO] Save training_log data...
2023-05-28 11:05:35,204 [INFO] Save score_log data...
2023-05-28 11:05:35,205 [INFO] Time : 2.3855245113372803
