2023-05-28 22:46:20,077 [INFO] Train data : Vary_params_IGF1R_KIT\DUD-E\KIT\nG1_80\ECFP4_512bits\MinMax\KIT_train_vector.tsv
2023-05-28 22:46:20,078 [INFO] Valid data : Vary_params_IGF1R_KIT\DUD-E\KIT\nG1_80\ECFP4_512bits\MinMax\KIT_valid_vector.tsv
2023-05-28 22:46:20,078 [INFO] Output path : Vary_params_IGF1R_KIT\DUD-E\KIT\nG1_80\ECFP4_512bits\MinMax\KIT_model\SVM
2023-05-28 22:46:20,078 [INFO] Model type : SVM
2023-05-28 22:46:20,078 [INFO] Use cores : 10
2023-05-28 22:46:20,100 [INFO] Start Learning model
2023-05-28 22:46:20,100 [INFO] Train : 202 | Valid : 58
2023-05-28 22:46:20,100 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 22:46:22,955 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.960238              0.985714        0.942857
22             0.990238              0.985714        0.989286
26             0.990238              0.985714        0.989286
28             0.990238              0.985714        0.989286
31             0.990238              0.985714        0.989286
32             0.990238              0.985714        0.989286
34             0.990238              0.985714        0.989286
36             0.990238              0.985714        0.989286
38             0.990238              0.985714        0.989286
40             0.990238              0.985714        0.989286
41             0.990238              0.985714        0.989286
42             0.990238              0.985714        0.989286
44             0.990238              0.985714        0.989286
46             0.990238              0.985714        0.989286
48             0.990238              0.985714        0.989286
50             0.990238              0.985714        0.989286
51             0.990238              0.985714        0.989286
52             0.990238              0.985714        0.989286
54             0.990238              0.985714        0.989286
56             0.990238              0.985714        0.989286
58             0.990238              0.985714        0.989286
24             0.990238              0.985714        0.989286
30             0.990238              0.985714        0.989286
12             0.990238              0.985714        0.989286
14             0.990238              0.985714        0.989286
2              0.960238              0.985714        0.942857
20             0.990238              0.985714        0.989286
4              0.960238              0.985714        0.942857
6              0.960238              0.985714        0.942857
8              0.960238              0.985714        0.942857
18             0.990238              0.985714        0.989286
10             0.990238              0.985714        0.989286
16             0.990238              0.985714        0.989286
21             0.965238              0.985714        0.950000
53             0.767619              0.800000        0.628571
43             0.767619              0.800000        0.628571
23             0.747857              0.800000        0.596429
33             0.767619              0.800000        0.628571
37             0.688333              0.000000        0.500000
49             0.688333              0.000000        0.500000
25             0.688333              0.000000        0.500000
57             0.688333              0.000000        0.500000
3              0.688333              0.000000        0.500000
55             0.688333              0.000000        0.500000
27             0.688333              0.000000        0.500000
19             0.688333              0.000000        0.500000
5              0.688333              0.000000        0.500000
29             0.688333              0.000000        0.500000
7              0.688333              0.000000        0.500000
1              0.688333              0.000000        0.500000
15             0.688333              0.000000        0.500000
47             0.688333              0.000000        0.500000
9              0.688333              0.000000        0.500000
45             0.688333              0.000000        0.500000
17             0.688333              0.000000        0.500000
11             0.688333              0.000000        0.500000
35             0.688333              0.000000        0.500000
13             0.688333              0.000000        0.500000
39             0.688333              0.000000        0.500000
59             0.688333              0.000000        0.500000
2023-05-28 22:46:22,956 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-28 22:46:22,963 [INFO] Save train_prediction_log data...
2023-05-28 22:46:22,966 [INFO] {'Data': 'train', 'ACC': '1.0 (201 / 202)', 'TP': 62, 'FP': 0, 'FN': 1, 'TN': 139, 'Precision': '1.0 (62 / 62 + 0)', 'Recall': '0.98 (62 / 62 + 1)', 'F1': '0.99 (2 * (0.98 * 1.0) / 0.98 + 1.0)', 'Specificity': '1.0 (139 / 139 + 0)', 'AUC': 0.99, 'r2': 0.98}
2023-05-28 22:46:22,971 [INFO] Save valid_prediction_log data...
2023-05-28 22:46:23,120 [INFO] {'Data': 'valid', 'ACC': '0.98 (57 / 58)', 'TP': 23, 'FP': 1, 'FN': 0, 'TN': 34, 'Precision': '0.96 (23 / 23 + 1)', 'Recall': '1.0 (23 / 23 + 0)', 'F1': '0.98 (2 * (1.0 * 0.96) / 1.0 + 0.96)', 'Specificity': '0.97 (34 / 34 + 1)', 'AUC': 0.99, 'r2': 0.93}
2023-05-28 22:46:23,135 [INFO] Save test_prediction_log data...
2023-05-28 22:46:23,137 [INFO] {'Data': 'test', 'ACC': '0.67 (39 / 58)', 'TP': 8, 'FP': 4, 'FN': 15, 'TN': 31, 'Precision': '0.67 (8 / 8 + 4)', 'Recall': '0.35 (8 / 8 + 15)', 'F1': '0.46 (2 * (0.35 * 0.67) / 0.35 + 0.67)', 'Specificity': '0.89 (31 / 31 + 4)', 'AUC': 0.62, 'r2': -0.37}
2023-05-28 22:46:23,139 [INFO] Save training_log data...
2023-05-28 22:46:23,140 [INFO] Save score_log data...
2023-05-28 22:46:23,140 [INFO] Time : 3.0632081031799316
