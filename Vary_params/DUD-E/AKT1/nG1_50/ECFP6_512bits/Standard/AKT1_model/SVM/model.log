2023-05-27 02:24:04,192 [INFO] Train data : Vary_params\DUD-E\AKT1\nG1_50\ECFP6_512bits\Standard\AKT1_train_vector.tsv
2023-05-27 02:24:04,192 [INFO] Valid data : Vary_params\DUD-E\AKT1\nG1_50\ECFP6_512bits\Standard\AKT1_valid_vector.tsv
2023-05-27 02:24:04,192 [INFO] Output path : Vary_params\DUD-E\AKT1\nG1_50\ECFP6_512bits\Standard\AKT1_model\SVM
2023-05-27 02:24:04,192 [INFO] Model type : SVM
2023-05-27 02:24:04,192 [INFO] Use cores : 11
2023-05-27 02:24:04,257 [INFO] Start Learning model
2023-05-27 02:24:04,257 [INFO] Train : 481 | Valid : 120
2023-05-27 02:24:04,257 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-27 02:24:10,946 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.989711                  0.99        0.989052
20             0.989711                  0.99        0.989052
24             0.989711                  0.99        0.989052
26             0.989711                  0.99        0.989052
28             0.989711                  0.99        0.989052
32             0.989711                  0.99        0.989052
34             0.989711                  0.99        0.989052
36             0.989711                  0.99        0.989052
38             0.989711                  0.99        0.989052
40             0.989711                  0.99        0.989052
42             0.989711                  0.99        0.989052
44             0.989711                  0.99        0.989052
46             0.989711                  0.99        0.989052
48             0.989711                  0.99        0.989052
50             0.989711                  0.99        0.989052
52             0.989711                  0.99        0.989052
54             0.989711                  0.99        0.989052
56             0.989711                  0.99        0.989052
58             0.989711                  0.99        0.989052
22             0.989711                  0.99        0.989052
30             0.989711                  0.99        0.989052
2              0.989711                  0.99        0.989052
18             0.989711                  0.99        0.989052
10             0.989711                  0.99        0.989052
8              0.989711                  0.99        0.989052
16             0.989711                  0.99        0.989052
4              0.989711                  0.99        0.989052
12             0.989711                  0.99        0.989052
14             0.989711                  0.99        0.989052
6              0.989711                  0.99        0.989052
21             0.652934                  0.90        0.565526
41             0.694600                  0.90        0.618026
31             0.694600                  0.90        0.618026
51             0.694600                  0.90        0.618026
7              0.600850                  0.00        0.500000
47             0.600850                  0.00        0.500000
5              0.600850                  0.00        0.500000
49             0.600850                  0.00        0.500000
9              0.600850                  0.00        0.500000
53             0.600850                  0.00        0.500000
55             0.600850                  0.00        0.500000
3              0.600850                  0.00        0.500000
57             0.600850                  0.00        0.500000
45             0.600850                  0.00        0.500000
11             0.600850                  0.00        0.500000
43             0.600850                  0.00        0.500000
19             0.600850                  0.00        0.500000
39             0.600850                  0.00        0.500000
37             0.600850                  0.00        0.500000
13             0.600850                  0.00        0.500000
35             0.600850                  0.00        0.500000
33             0.600850                  0.00        0.500000
15             0.600850                  0.00        0.500000
1              0.600850                  0.00        0.500000
29             0.600850                  0.00        0.500000
27             0.600850                  0.00        0.500000
17             0.600850                  0.00        0.500000
25             0.600850                  0.00        0.500000
23             0.600850                  0.00        0.500000
59             0.600850                  0.00        0.500000
2023-05-27 02:24:10,949 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-27 02:24:10,963 [INFO] Save train_prediction_log data...
2023-05-27 02:24:10,969 [INFO] {'Data': 'train', 'ACC': '1.0 (481 / 481)', 'TP': 192, 'FP': 0, 'FN': 0, 'TN': 289, 'Precision': '1.0 (192 / 192 + 0)', 'Recall': '1.0 (192 / 192 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (289 / 289 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-27 02:24:10,977 [INFO] Save valid_prediction_log data...
2023-05-27 02:24:10,979 [INFO] {'Data': 'valid', 'ACC': '0.99 (119 / 120)', 'TP': 48, 'FP': 1, 'FN': 0, 'TN': 71, 'Precision': '0.98 (48 / 48 + 1)', 'Recall': '1.0 (48 / 48 + 0)', 'F1': '0.99 (2 * (1.0 * 0.98) / 1.0 + 0.98)', 'Specificity': '0.99 (71 / 71 + 1)', 'AUC': 0.99, 'r2': 0.97}
2023-05-27 02:24:11,007 [INFO] Save test_prediction_log data...
2023-05-27 02:24:11,010 [INFO] {'Data': 'test', 'ACC': '0.71 (85 / 120)', 'TP': 22, 'FP': 9, 'FN': 26, 'TN': 63, 'Precision': '0.71 (22 / 22 + 9)', 'Recall': '0.46 (22 / 22 + 26)', 'F1': '0.56 (2 * (0.46 * 0.71) / 0.46 + 0.71)', 'Specificity': '0.88 (63 / 63 + 9)', 'AUC': 0.67, 'r2': -0.22}
2023-05-27 02:24:11,013 [INFO] Save training_log data...
2023-05-27 02:24:11,014 [INFO] Save score_log data...
2023-05-27 02:24:11,014 [INFO] Time : 6.822596073150635
