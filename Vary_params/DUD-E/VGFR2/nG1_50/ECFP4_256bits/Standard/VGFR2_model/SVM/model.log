2023-05-29 00:08:29,930 [INFO] Train data : Vary_params_VGFR2\DUD-E\VGFR2\nG1_50\ECFP4_256bits\Standard\VGFR2_train_vector.tsv
2023-05-29 00:08:29,930 [INFO] Valid data : Vary_params_VGFR2\DUD-E\VGFR2\nG1_50\ECFP4_256bits\Standard\VGFR2_valid_vector.tsv
2023-05-29 00:08:29,930 [INFO] Output path : Vary_params_VGFR2\DUD-E\VGFR2\nG1_50\ECFP4_256bits\Standard\VGFR2_model\SVM
2023-05-29 00:08:29,930 [INFO] Model type : SVM
2023-05-29 00:08:29,930 [INFO] Use cores : 18
2023-05-29 00:08:29,984 [INFO] Start Learning model
2023-05-29 00:08:29,984 [INFO] Train : 717 | Valid : 180
2023-05-29 00:08:29,984 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-29 00:08:36,263 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
31             0.941491              1.000000        0.927032
21             0.927563              1.000000        0.909667
51             0.941491              1.000000        0.927032
41             0.941491              1.000000        0.927032
0              0.941432              0.931215        0.938444
2              0.941432              0.931215        0.938444
4              0.941432              0.931215        0.938444
6              0.941432              0.931215        0.938444
8              0.941432              0.931215        0.938444
42             0.927445              0.898229        0.926816
32             0.927445              0.898229        0.926816
34             0.927445              0.898229        0.926816
36             0.927445              0.898229        0.926816
38             0.927445              0.898229        0.926816
40             0.927445              0.898229        0.926816
48             0.927445              0.898229        0.926816
44             0.927445              0.898229        0.926816
46             0.927445              0.898229        0.926816
26             0.927445              0.898229        0.926816
50             0.927445              0.898229        0.926816
52             0.927445              0.898229        0.926816
54             0.927445              0.898229        0.926816
56             0.927445              0.898229        0.926816
58             0.927445              0.898229        0.926816
28             0.927445              0.898229        0.926816
30             0.927445              0.898229        0.926816
18             0.927445              0.898229        0.926816
24             0.927445              0.898229        0.926816
14             0.927445              0.898229        0.926816
12             0.927445              0.898229        0.926816
22             0.927445              0.898229        0.926816
16             0.927445              0.898229        0.926816
20             0.927445              0.898229        0.926816
10             0.927445              0.898229        0.926816
25             0.599746              0.000000        0.500000
49             0.599746              0.000000        0.500000
11             0.599746              0.000000        0.500000
53             0.599746              0.000000        0.500000
9              0.599746              0.000000        0.500000
13             0.599746              0.000000        0.500000
7              0.599746              0.000000        0.500000
55             0.599746              0.000000        0.500000
5              0.599746              0.000000        0.500000
57             0.599746              0.000000        0.500000
3              0.599746              0.000000        0.500000
47             0.599746              0.000000        0.500000
43             0.599746              0.000000        0.500000
45             0.599746              0.000000        0.500000
27             0.599746              0.000000        0.500000
15             0.599746              0.000000        0.500000
17             0.599746              0.000000        0.500000
39             0.599746              0.000000        0.500000
37             0.599746              0.000000        0.500000
19             0.599746              0.000000        0.500000
35             0.599746              0.000000        0.500000
33             0.599746              0.000000        0.500000
23             0.599746              0.000000        0.500000
1              0.599746              0.000000        0.500000
29             0.599746              0.000000        0.500000
59             0.599746              0.000000        0.500000
2023-05-29 00:08:36,264 [INFO] Best model :
SVC(C=1, gamma=0.01, random_state=42)
2023-05-29 00:08:36,359 [INFO] Save train_prediction_log data...
2023-05-29 00:08:36,363 [INFO] {'Data': 'train', 'ACC': '1.0 (717 / 717)', 'TP': 287, 'FP': 0, 'FN': 0, 'TN': 430, 'Precision': '1.0 (287 / 287 + 0)', 'Recall': '1.0 (287 / 287 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (430 / 430 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-29 00:08:36,390 [INFO] Save valid_prediction_log data...
2023-05-29 00:08:36,393 [INFO] {'Data': 'valid', 'ACC': '1.0 (180 / 180)', 'TP': 72, 'FP': 0, 'FN': 0, 'TN': 108, 'Precision': '1.0 (72 / 72 + 0)', 'Recall': '1.0 (72 / 72 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (108 / 108 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-29 00:08:36,434 [INFO] Save test_prediction_log data...
2023-05-29 00:08:36,437 [INFO] {'Data': 'test', 'ACC': '0.63 (114 / 180)', 'TP': 16, 'FP': 10, 'FN': 56, 'TN': 98, 'Precision': '0.62 (16 / 16 + 10)', 'Recall': '0.22 (16 / 16 + 56)', 'F1': '0.32 (2 * (0.22 * 0.62) / 0.22 + 0.62)', 'Specificity': '0.91 (98 / 98 + 10)', 'AUC': 0.56, 'r2': -0.53}
2023-05-29 00:08:36,440 [INFO] Save training_log data...
2023-05-29 00:08:36,442 [INFO] Save score_log data...
2023-05-29 00:08:36,443 [INFO] Time : 6.512612819671631
