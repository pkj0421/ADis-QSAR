2023-05-28 22:53:40,410 [INFO] Train data : Vary_params_ABL_BRAF_FGFR1\DUD-E\ABL1\nG1_80\ECFP4_512bits\Robust\ABL1_train_vector.tsv
2023-05-28 22:53:40,410 [INFO] Valid data : Vary_params_ABL_BRAF_FGFR1\DUD-E\ABL1\nG1_80\ECFP4_512bits\Robust\ABL1_valid_vector.tsv
2023-05-28 22:53:40,410 [INFO] Output path : Vary_params_ABL_BRAF_FGFR1\DUD-E\ABL1\nG1_80\ECFP4_512bits\Robust\ABL1_model\SVM
2023-05-28 22:53:40,411 [INFO] Model type : SVM
2023-05-28 22:53:40,411 [INFO] Use cores : 19
2023-05-28 22:53:40,431 [INFO] Start Learning model
2023-05-28 22:53:40,431 [INFO] Train : 234 | Valid : 66
2023-05-28 22:53:40,432 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-28 22:53:44,167 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
0              0.961957                0.9625        0.952232
20             0.961957                0.9625        0.952232
24             0.961957                0.9625        0.952232
26             0.961957                0.9625        0.952232
28             0.961957                0.9625        0.952232
32             0.961957                0.9625        0.952232
34             0.961957                0.9625        0.952232
36             0.961957                0.9625        0.952232
38             0.961957                0.9625        0.952232
40             0.961957                0.9625        0.952232
42             0.961957                0.9625        0.952232
44             0.961957                0.9625        0.952232
46             0.961957                0.9625        0.952232
48             0.961957                0.9625        0.952232
50             0.961957                0.9625        0.952232
52             0.961957                0.9625        0.952232
54             0.961957                0.9625        0.952232
56             0.961957                0.9625        0.952232
58             0.961957                0.9625        0.952232
22             0.961957                0.9625        0.952232
30             0.961957                0.9625        0.952232
10             0.961957                0.9625        0.952232
2              0.961957                0.9625        0.952232
18             0.961957                0.9625        0.952232
8              0.961957                0.9625        0.952232
16             0.961957                0.9625        0.952232
4              0.961957                0.9625        0.952232
12             0.961957                0.9625        0.952232
6              0.961957                0.9625        0.952232
14             0.961957                0.9625        0.952232
49             0.675362                0.0000        0.500000
9              0.675362                0.0000        0.500000
45             0.675362                0.0000        0.500000
47             0.675362                0.0000        0.500000
7              0.675362                0.0000        0.500000
21             0.675362                0.0000        0.500000
43             0.675362                0.0000        0.500000
5              0.675362                0.0000        0.500000
53             0.675362                0.0000        0.500000
55             0.675362                0.0000        0.500000
3              0.675362                0.0000        0.500000
57             0.675362                0.0000        0.500000
51             0.675362                0.0000        0.500000
11             0.675362                0.0000        0.500000
41             0.675362                0.0000        0.500000
19             0.675362                0.0000        0.500000
39             0.675362                0.0000        0.500000
37             0.675362                0.0000        0.500000
13             0.675362                0.0000        0.500000
35             0.675362                0.0000        0.500000
33             0.675362                0.0000        0.500000
15             0.675362                0.0000        0.500000
31             0.675362                0.0000        0.500000
1              0.675362                0.0000        0.500000
29             0.675362                0.0000        0.500000
27             0.675362                0.0000        0.500000
17             0.675362                0.0000        0.500000
25             0.675362                0.0000        0.500000
23             0.675362                0.0000        0.500000
59             0.675362                0.0000        0.500000
2023-05-28 22:53:44,169 [INFO] Best model :
SVC(C=0.01, gamma=0.01, kernel='linear', random_state=42)
2023-05-28 22:53:44,174 [INFO] Save train_prediction_log data...
2023-05-28 22:53:44,177 [INFO] {'Data': 'train', 'ACC': '1.0 (234 / 234)', 'TP': 76, 'FP': 0, 'FN': 0, 'TN': 158, 'Precision': '1.0 (76 / 76 + 0)', 'Recall': '1.0 (76 / 76 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (158 / 158 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 22:53:44,184 [INFO] Save valid_prediction_log data...
2023-05-28 22:53:44,185 [INFO] {'Data': 'valid', 'ACC': '1.0 (66 / 66)', 'TP': 26, 'FP': 0, 'FN': 0, 'TN': 40, 'Precision': '1.0 (26 / 26 + 0)', 'Recall': '1.0 (26 / 26 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (40 / 40 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-28 22:53:44,198 [INFO] Save test_prediction_log data...
2023-05-28 22:53:44,200 [INFO] {'Data': 'test', 'ACC': '0.65 (43 / 66)', 'TP': 9, 'FP': 6, 'FN': 17, 'TN': 34, 'Precision': '0.6 (9 / 9 + 6)', 'Recall': '0.35 (9 / 9 + 17)', 'F1': '0.44 (2 * (0.35 * 0.6) / 0.35 + 0.6)', 'Specificity': '0.85 (34 / 34 + 6)', 'AUC': 0.6, 'r2': -0.46}
2023-05-28 22:53:44,201 [INFO] Save training_log data...
2023-05-28 22:53:44,203 [INFO] Save score_log data...
2023-05-28 22:53:44,204 [INFO] Time : 3.793947458267212
