2023-05-29 04:04:17,484 [INFO] Train data : Baseline_noscale\ChEMBL\BTK\ECFP6_256bits\BTK_raw_train.tsv
2023-05-29 04:04:17,484 [INFO] Valid data : Baseline_noscale\ChEMBL\BTK\ECFP6_256bits\BTK_raw_valid.tsv
2023-05-29 04:04:17,484 [INFO] Output path : Baseline_noscale\ChEMBL\BTK\ECFP6_256bits\BTK_model\SVM
2023-05-29 04:04:17,484 [INFO] Model type : SVM
2023-05-29 04:04:17,484 [INFO] Use cores : 12
2023-05-29 04:04:17,497 [INFO] Start Learning model
2023-05-29 04:04:17,498 [INFO] Train : 608 | Valid : 152
2023-05-29 04:04:17,498 [INFO] Set parameters : {'kernel': ['linear', 'rbf'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 100, 1000]}
2023-05-29 04:04:21,198 [INFO] GridSearchCV results :
    mean_valid_accuracy  mean_valid_precision  mean_valid_auc
23             0.633197              1.000000        0.541167
33             0.649645              0.975000        0.562315
53             0.649645              0.975000        0.562315
43             0.649645              0.975000        0.562315
21             0.927596              0.932937        0.920632
0              0.922596              0.927433        0.915077
2              0.922596              0.927433        0.915077
4              0.922596              0.927433        0.915077
6              0.922596              0.927433        0.915077
8              0.922596              0.927433        0.915077
51             0.927678              0.912233        0.924828
41             0.927678              0.912233        0.924828
31             0.927678              0.912233        0.924828
12             0.909617              0.891550        0.905496
18             0.909617              0.891550        0.905496
14             0.909617              0.891550        0.905496
10             0.909617              0.891550        0.905496
16             0.909617              0.891550        0.905496
48             0.898005              0.875600        0.893812
32             0.898005              0.875600        0.893812
46             0.898005              0.875600        0.893812
44             0.898005              0.875600        0.893812
52             0.898005              0.875600        0.893812
50             0.898005              0.875600        0.893812
54             0.898005              0.875600        0.893812
42             0.898005              0.875600        0.893812
56             0.898005              0.875600        0.893812
40             0.898005              0.875600        0.893812
38             0.898005              0.875600        0.893812
36             0.898005              0.875600        0.893812
34             0.898005              0.875600        0.893812
58             0.898005              0.875600        0.893812
30             0.898005              0.875600        0.893812
28             0.898005              0.875600        0.893812
26             0.898005              0.875600        0.893812
24             0.898005              0.875600        0.893812
22             0.898005              0.875600        0.893812
20             0.898005              0.875600        0.893812
11             0.610246              0.500000        0.512417
1              0.600328              0.000000        0.500000
49             0.600328              0.000000        0.500000
3              0.600328              0.000000        0.500000
57             0.600328              0.000000        0.500000
5              0.600328              0.000000        0.500000
55             0.600328              0.000000        0.500000
7              0.600328              0.000000        0.500000
9              0.600328              0.000000        0.500000
13             0.600328              0.000000        0.500000
15             0.600328              0.000000        0.500000
19             0.600328              0.000000        0.500000
17             0.600328              0.000000        0.500000
47             0.600328              0.000000        0.500000
29             0.600328              0.000000        0.500000
45             0.600328              0.000000        0.500000
25             0.600328              0.000000        0.500000
39             0.600328              0.000000        0.500000
27             0.600328              0.000000        0.500000
37             0.600328              0.000000        0.500000
35             0.600328              0.000000        0.500000
59             0.600328              0.000000        0.500000
2023-05-29 04:04:21,200 [INFO] Best model :
SVC(C=1, gamma=0.1, random_state=42)
2023-05-29 04:04:21,238 [INFO] Save train_prediction_log data...
2023-05-29 04:04:21,242 [INFO] {'Data': 'train', 'ACC': '1.0 (608 / 608)', 'TP': 243, 'FP': 0, 'FN': 0, 'TN': 365, 'Precision': '1.0 (243 / 243 + 0)', 'Recall': '1.0 (243 / 243 + 0)', 'F1': '1.0 (2 * (1.0 * 1.0) / 1.0 + 1.0)', 'Specificity': '1.0 (365 / 365 + 0)', 'AUC': 1.0, 'r2': 1.0}
2023-05-29 04:04:21,253 [INFO] Save valid_prediction_log data...
2023-05-29 04:04:21,255 [INFO] {'Data': 'valid', 'ACC': '0.66 (101 / 152)', 'TP': 10, 'FP': 0, 'FN': 51, 'TN': 91, 'Precision': '1.0 (10 / 10 + 0)', 'Recall': '0.16 (10 / 10 + 51)', 'F1': '0.28 (2 * (0.16 * 1.0) / 0.16 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.58, 'r2': -0.4}
2023-05-29 04:04:21,270 [INFO] Save test_prediction_log data...
2023-05-29 04:04:21,272 [INFO] {'Data': 'test', 'ACC': '0.68 (103 / 151)', 'TP': 12, 'FP': 0, 'FN': 48, 'TN': 91, 'Precision': '1.0 (12 / 12 + 0)', 'Recall': '0.2 (12 / 12 + 48)', 'F1': '0.33 (2 * (0.2 * 1.0) / 0.2 + 1.0)', 'Specificity': '1.0 (91 / 91 + 0)', 'AUC': 0.6, 'r2': -0.33}
2023-05-29 04:04:21,275 [INFO] Save training_log data...
2023-05-29 04:04:21,275 [INFO] Save score_log data...
2023-05-29 04:04:21,277 [INFO] Time : 3.7929418087005615
